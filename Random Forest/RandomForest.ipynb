{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dmUlHGAp4Y2n"
   },
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9pgTIDvOh_Fo"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "Yb-N6JT-ilKG"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "RIdS9fyDimhF",
    "outputId": "bf757024-d501-48b9-a859-4e245bb80224"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-9fbda4e7-4fa5-4da9-b7af-8d7ebad9c360\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9fbda4e7-4fa5-4da9-b7af-8d7ebad9c360')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-9fbda4e7-4fa5-4da9-b7af-8d7ebad9c360 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-9fbda4e7-4fa5-4da9-b7af-8d7ebad9c360');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
       "0            5.1           3.5            1.4           0.2  Iris-setosa\n",
       "1            4.9           3.0            1.4           0.2  Iris-setosa\n",
       "2            4.7           3.2            1.3           0.2  Iris-setosa\n",
       "3            4.6           3.1            1.5           0.2  Iris-setosa\n",
       "4            5.0           3.6            1.4           0.2  Iris-setosa"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/content/sample_data/Iris.csv')\n",
    "df = df.drop(\"Id\", axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "v_QgZUfzjJgd"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(df['Species'])\n",
    "\n",
    "df['Species'] = encoder.transform(df['Species'])\n",
    "\n",
    "X = df[df.columns.to_list()[:-1]]\n",
    "y = df['Species']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 121)#, test_size = 0.32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2HFJtUpWjZ9F"
   },
   "source": [
    "# <b> Descison Tree algorithm </b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "UaP20dhojJx9"
   },
   "outputs": [],
   "source": [
    "class DescisionTree:\n",
    "  def __init__(self, min_samples_leaf, min_samples_split, max_depth, criterion, max_features, ml_task):\n",
    "    self.data = None\n",
    "    self.X = None\n",
    "    self.y = None\n",
    "    self.max_features = max_features\n",
    "    self.ml_task = ml_task\n",
    "    self.min_samples_leaf = min_samples_leaf\n",
    "    self.min_samples_split = min_samples_split\n",
    "    self.max_depth = max_depth\n",
    "    self.metric = criterion\n",
    "    self.feature_importances_ = None\n",
    "    self.complete_tree = None\n",
    "    self.n_entries = {}\n",
    "    self.n_weighted_entries = {}\n",
    "    self.parent_node = 1  # root node\n",
    "    self.yes_node = 2     # left node\n",
    "    self.no_node = 3      # right node\n",
    "    self.leaf_count = 0\n",
    "    if ml_task == 'classification': self.classes_and_counts = {};self.leaf_node_class_proba = {}\n",
    "    else: self.leaf_node_loss = {}\n",
    "\n",
    "  ''' This method is used to get the collective counts of all classes in target '''\n",
    "  def get_classes_and_counts(self, data):\n",
    "    label_column = data[:, -1]\n",
    "    unique_classes, counts_unique_classes = np.unique(label_column, return_counts=True)\n",
    "    for i in range(len(unique_classes)):\n",
    "      self.classes_and_counts[unique_classes[i]] = counts_unique_classes[i]\n",
    "\n",
    "  ''' This method is used to get the collective probabilities of all classes in target '''\n",
    "  def get_probability_for_all_classes(self, data):\n",
    "    label_column = data[:, -1]\n",
    "    unique_classes_new, counts_unique_classes_new = np.unique(label_column, return_counts=True)\n",
    "    \n",
    "    classes_and_counts_new = {}\n",
    "    for i in list(self.classes_and_counts.keys()):\n",
    "      if i in list(unique_classes_new):\n",
    "        classes_and_counts_new[i] = counts_unique_classes_new[list(unique_classes_new).index(i)]\n",
    "      else:\n",
    "        classes_and_counts_new[i] = 0\n",
    "    array = np.array(list(classes_and_counts_new.values())) / sum(classes_and_counts_new.values())\n",
    "\n",
    "    return [round(i, 5) for i in array]\n",
    "\n",
    "\n",
    "  ''' This method checks the purity of a target vector '''\n",
    "  def check_purity(self, data):\n",
    "      label_column = data[:, -1]\n",
    "      unique_classes = np.unique(label_column)\n",
    "      if len(unique_classes) == 1:\n",
    "          return True\n",
    "      else:\n",
    "          return False\n",
    "\n",
    "\n",
    "  ''' This method performs classification '''\n",
    "  def create_leaf(self, data, ml_task, current_node):\n",
    "      self.leaf_count += 1\n",
    "      label_column = data[:, -1]\n",
    "      if ml_task == \"regression\":\n",
    "          leaf = np.mean(label_column)\n",
    "          self.leaf_node_loss[current_node] = self.mse(data)\n",
    "          return str(leaf) + ' Node: '+str(current_node)\n",
    "      else:\n",
    "          probabilities = []\n",
    "          unique_classes, counts_unique_classes = np.unique(label_column, return_counts=True)\n",
    "          index = counts_unique_classes.argmax()\n",
    "          leaf = unique_classes[index]\n",
    "          # probability = counts_unique_classes[index] / sum(counts_unique_classes)\n",
    "          self.leaf_node_class_proba[current_node] = self.get_probability_for_all_classes(data)\n",
    "          \n",
    "          return str(leaf) + ' Node: '+str(current_node)\n",
    "    \n",
    "    \n",
    "  ''' this function generates all possible potential splits for a given training data '''\n",
    "  def get_potential_splits(self, data, random_subspace):  # randomly selecting certain features\n",
    "    potential_splits = {}\n",
    "    _, n_columns = data.shape\n",
    "    column_indices = list(range(n_columns - 1))    # excluding the last column which is the label\n",
    "    if random_subspace and random_subspace <= len(column_indices):\n",
    "        column_indices = random.sample(population=column_indices, k=random_subspace)\n",
    "    for column_index in column_indices:          \n",
    "        values = data[:, column_index]\n",
    "        unique_values = np.unique(values)\n",
    "        potential_splits[column_index] = unique_values\n",
    "\n",
    "    return potential_splits\n",
    "    \n",
    "    \n",
    "  ''' This function splits the data into two partitions: Yes and no cases'''\n",
    "  def split_data(self, data, split_column, split_value):\n",
    "      split_column_values = data[:, split_column]\n",
    "      type_of_feature = FEATURE_TYPES[split_column]\n",
    "\n",
    "      if type_of_feature == \"continuous\":\n",
    "          data_below = data[split_column_values <= split_value]\n",
    "          data_above = data[split_column_values >  split_value]\n",
    "      else:\n",
    "          data_below = data[split_column_values == split_value]\n",
    "          data_above = data[split_column_values != split_value]\n",
    "      \n",
    "      return data_below, data_above\n",
    "    \n",
    "    \n",
    "  ''' This method calculates mse loss'''\n",
    "  def mse(self, data):\n",
    "      actual_values = data[:, -1]\n",
    "      if len(actual_values) == 0:   # empty data\n",
    "          mse = 0\n",
    "      else:\n",
    "          prediction = np.mean(actual_values)\n",
    "          mse = np.mean((actual_values - prediction) **2)\n",
    "      \n",
    "      return mse\n",
    "\n",
    "  ''' This method calculates entropy loss '''\n",
    "  def entropy(self, data):\n",
    "      label_column = data[:, -1]\n",
    "      _, counts = np.unique(label_column, return_counts=True)\n",
    "      probabilities = counts / counts.sum()\n",
    "      entropy = sum(probabilities * -np.log2(probabilities))\n",
    "      \n",
    "      return entropy\n",
    "\n",
    "\n",
    "  ''' This method calculates gini impurity'''\n",
    "  def gini(self, data):\n",
    "    label_column = data[:, -1]\n",
    "    _, counts = np.unique(label_column, return_counts=True)\n",
    "    probabilities = counts / counts.sum()\n",
    "    gini_index = 0\n",
    "\n",
    "    for i in probabilities:\n",
    "      gini_index += i ** 2\n",
    "    \n",
    "    return 1 - gini_index\n",
    "\n",
    "\n",
    "  ''' calculating total/weighed value of the used metric '''\n",
    "  def calculate_overall_metric(self, data_below, data_above, metric_function):\n",
    "    n = len(data_below) + len(data_above)\n",
    "    p_data_below = len(data_below) / n\n",
    "    p_data_above = len(data_above) / n\n",
    "    # weighted MSE, RMSE, Gini, and entropy\n",
    "    overall_metric =  (p_data_below * metric_function(self, data_below) \n",
    "                     + p_data_above * metric_function(self, data_above))\n",
    "    \n",
    "    return overall_metric\n",
    "\n",
    "\n",
    "  \n",
    "  ''' Determining which split is the best by using the metric '''\n",
    "  def determine_best_split(self, data, potential_splits, ml_task, criterion):\n",
    "    first_iteration = True\n",
    "    for column_index in potential_splits:\n",
    "        for value in potential_splits[column_index]:\n",
    "            data_below, data_above = self.split_data(data, split_column=column_index, split_value=value)\n",
    "            \n",
    "        \n",
    "            current_overall_metric = self.calculate_overall_metric(data_below, data_above, metric_function=criterion)\n",
    "            if first_iteration or current_overall_metric <= best_overall_metric:\n",
    "                first_iteration = False\n",
    "                best_overall_metric = current_overall_metric\n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "    \n",
    "    return best_split_column, best_split_value\n",
    "\n",
    "\n",
    "  ''' determining the type of a feature among all features '''\n",
    "  def determine_type_of_feature(self, df):\n",
    "    feature_types = []\n",
    "    n_unique_values_treshold = 10\n",
    "\n",
    "    for feature in df.columns:\n",
    "        if feature != \"label\":\n",
    "            unique_values = df[feature].unique()\n",
    "            example_value = unique_values[0]\n",
    "            if (isinstance(example_value, str)) or (len(unique_values) <= n_unique_values_treshold):\n",
    "                feature_types.append(\"categorical\")\n",
    "            else:\n",
    "                feature_types.append(\"continuous\")\n",
    "    \n",
    "    return feature_types\n",
    " \n",
    "    \n",
    "  ''' THIS IS THE MAIN RECURSIVE ALGORITHM FOR DESCISION TREE'''\n",
    "\n",
    "  def tree(self, df, ml_task, counter,current_node, min_samples_leaf, min_samples_split,max_depth, criterion, answer, max_features):\n",
    "\n",
    "    # When the tree starts, the dataframe is converteed to numpy array, the depth of the tree is checked using counter variable and all features types are detected\n",
    "    if counter == 0:\n",
    "        global COLUMN_HEADERS, FEATURE_TYPES\n",
    "        COLUMN_HEADERS = df.columns\n",
    "        FEATURE_TYPES = self.determine_type_of_feature(df)\n",
    "        data = df.values\n",
    "        criterion = getattr(DescisionTree, criterion)\n",
    "    else:\n",
    "        data = df      \n",
    "\n",
    "    # storing the length of data passed into the node\n",
    "    self.n_entries['Node: '+str(current_node)] = [len(df)]\n",
    "    # criterion = getattr(DescisionTree, criterion)\n",
    "\n",
    "    # storing the loss/mse/rmse/gini/entropy in a specific node\n",
    "    self.n_entries['Node: '+str(current_node)].append(criterion(self, data))\n",
    "    \n",
    "    # incrementing yes/left nodes and no/right nodes such that yes will be a even node and no will be a odd node repectively\n",
    "    if (answer == 'yes answer'):\n",
    "      self.yes_node += 2\n",
    "    elif (answer == 'no answer'):\n",
    "      self.no_node += 2 \n",
    "      \n",
    "    # checking if that target of the data passed is either pure, has minimum samples to create a leaf, or the depth of tree has reached its maximum depth\n",
    "    if (self.check_purity(data)) or (len(data) == min_samples_leaf) or (counter == max_depth):\n",
    "        leaf = self.create_leaf(data, ml_task, current_node) # creating the leaf\n",
    "        return leaf \n",
    "    # if above requirements to create a leaf are not met, two new nodes will be created recursively respectively.\n",
    "    else:    \n",
    "        counter += 1 # when two new nodes are created, the depth of three is also incremented\n",
    "        \n",
    "        # if the data is not yet pure, but has not minimum samples to perform the split, a leaf is created\n",
    "        if (len(data) < min_samples_split):\n",
    "          leaf = self.create_leaf(data, ml_task, current_node)\n",
    "          return leaf\n",
    "        else:\n",
    "          # getting the all possible splits, determining which split has least loss, and splitting the data into left and right nodes respectively\n",
    "          potential_splits = self.get_potential_splits(data, max_features)\n",
    "          split_column, split_value = self.determine_best_split(data, potential_splits, ml_task,criterion)\n",
    "          data_below, data_above = self.split_data(data, split_column, split_value)\n",
    "          \n",
    "          # if the data seperated into left and right nodes, but there is no data, instead of creating a node, a leaft is created\n",
    "          if len(data_below) == 0 or len(data_above) == 0:\n",
    "              leaf = self.create_leaf(data, ml_task, current_node)\n",
    "              return leaf\n",
    "          \n",
    "          # finding the type of a selected feature column and its name\n",
    "          feature_name = COLUMN_HEADERS[split_column]\n",
    "          type_of_feature = FEATURE_TYPES[split_column]\n",
    "\n",
    "#           # creating the tree questions\n",
    "          if type_of_feature == \"continuous\":\n",
    "              question = \"{} <= {} (Node: {})\".format(feature_name, split_value, current_node)\n",
    "          # feature is categorical\n",
    "          else:\n",
    "              question = \"{} = {} (Node: {})\".format(feature_name, split_value, current_node)\n",
    "\n",
    "          # instantiate sub-tree\n",
    "          sub_tree = {question: []}\n",
    "\n",
    "          # creating left and right nodes recursively\n",
    "          yes_answer = self.tree(data_below, ml_task, counter, self.yes_node,min_samples_leaf, min_samples_split,max_depth, criterion, 'yes answer', max_features)\n",
    "          no_answer = self.tree(data_above, ml_task, counter, self.no_node,min_samples_leaf,min_samples_split, max_depth, criterion, 'no answer', max_features)\n",
    "          \n",
    "          # if both left and right nodes are same, only taking one value for a leaf node\n",
    "          if yes_answer == no_answer:\n",
    "              sub_tree = yes_answer\n",
    "          else:\n",
    "            sub_tree[question].append(yes_answer)\n",
    "            sub_tree[question].append(no_answer)\n",
    "          \n",
    "          return sub_tree\n",
    "\n",
    "    \n",
    "\n",
    "  ''' making probability of the predictions using this tree '''\n",
    "  def predict_example_probability(self, example, tree):\n",
    "    question = list(tree.keys())[0]\n",
    "    feature_name, comparison_operator, value = question.split(\" \")[:3]\n",
    "\n",
    "    # ask question\n",
    "    if comparison_operator == \"<=\":\n",
    "        if example[feature_name] <= float(value):\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "    # feature is categorical\n",
    "    else:\n",
    "        if str(example[feature_name]) == value:\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "    # base case\n",
    "    if not isinstance(answer, dict):\n",
    "        return int(answer.split()[2])\n",
    "            \n",
    "    # recursive part\n",
    "    else:\n",
    "        residual_tree = answer\n",
    "        return self.predict_example_probability(example, residual_tree)\n",
    "\n",
    "    \n",
    "  ''' fitting our tree with training data '''\n",
    "  def fit(self, X,y):\n",
    "    self.X = X.copy();self.y = y.copy()\n",
    "    self.X['label'] = self.y;self.data = self.X\n",
    "\n",
    "    if self.ml_task == 'classification':\n",
    "      self.get_classes_and_counts(self.data.values)\n",
    "    self.complete_tree = self.tree(self.data, self.ml_task, 0,self.parent_node, self.min_samples_leaf, self.min_samples_split, self.max_depth, self.metric,'parent_node', self.max_features)\n",
    "\n",
    "    # calculating weighted entries\n",
    "    for key, value in self.n_entries.items():\n",
    "      self.n_weighted_entries[key] = [value[0] / len(self.X), value[1]]\n",
    "\n",
    "    return self.complete_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D2OS1ji1jscW"
   },
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "vew5xGYqpMFX"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "oigvCUdJwOpk"
   },
   "outputs": [],
   "source": [
    "class RandomForest:\n",
    "  def __init__(self,criterion, n_estimators, n_bootstrap, ml_task, max_depth, max_features, min_samples_leaf = 1, min_samples_split = 2):\n",
    "    self.n_estimators = n_estimators\n",
    "    self.n_bootstrap = n_bootstrap\n",
    "    self.max_features = max_features\n",
    "    self.ml_task = ml_task\n",
    "    self.min_samples_leaf = min_samples_leaf\n",
    "    self.min_samples_split = min_samples_split\n",
    "    self.max_depth = max_depth\n",
    "    self.metric = criterion\n",
    "    self.forest = []\n",
    "    self.X = None\n",
    "    self.y = None\n",
    "    self.each_tree_with_class_probabilities = []\n",
    "    self.n_classes = None\n",
    "\n",
    "\n",
    "\n",
    "  ''' Performing boostraping '''\n",
    "  def bootstrapping(self, X,y, n_bootstrap):\n",
    "    bootstrap_indices = np.random.randint(low=0, high=len(X), size=int(n_bootstrap * len(X)))\n",
    "    bootstraped_X = X.iloc[bootstrap_indices]\n",
    "    bootstraped_y = y.iloc[bootstrap_indices]\n",
    "    \n",
    "    return bootstraped_X, bootstraped_y\n",
    "\n",
    "\n",
    "  ''' Training our model '''\n",
    "  def fit(self, X, y):\n",
    "    self.X = X.copy(); self.y = y.copy()\n",
    "    self.n_classes = len(np.unique(self.y.values))\n",
    "    for i in range(self.n_estimators):\n",
    "      bootstraped_X, bootstraped_y= self.bootstrapping(self.X,self.y, self.n_bootstrap)\n",
    "      tree = DescisionTree(min_samples_leaf = self.min_samples_leaf, min_samples_split = self.min_samples_split, max_depth =  self.max_depth, \\\n",
    "                           criterion = self.metric, max_features = self.max_features, ml_task = self.ml_task)\n",
    "      complete_tree = tree.fit(bootstraped_X, bootstraped_y)\n",
    "      # getting probabilities for each class for individual classes\n",
    "      if self.ml_task == 'classification':\n",
    "        probabilities_of_each_nodes = tree.leaf_node_class_proba\n",
    "        self.forest.append(complete_tree)\n",
    "        self.each_tree_with_class_probabilities.append(probabilities_of_each_nodes)\n",
    "      else:\n",
    "        self.forest.append(complete_tree)\n",
    "    \n",
    "    return 'Training completed'\n",
    "\n",
    "  ''' Making individual predictions '''\n",
    "  def predict_example(self, example, tree):\n",
    "    question = list(tree.keys())[0]\n",
    "    feature_name, comparison_operator, value = question.split(\" \")[:3]\n",
    "\n",
    "    # ask question\n",
    "    if comparison_operator == \"<=\":\n",
    "        if example[feature_name] <= float(value):\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "    # feature is categorical\n",
    "    else:\n",
    "        if str(example[feature_name]) == value:\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "    # base case\n",
    "    if not isinstance(answer, dict):\n",
    "        return float(answer.split()[0])\n",
    "    \n",
    "    # recursive part\n",
    "    else:\n",
    "        residual_tree = answer\n",
    "        return self.predict_example(example, residual_tree)\n",
    "\n",
    "\n",
    "\n",
    "  ''' Making predictions on testing dataframe '''\n",
    "  def decision_tree_predictions(self, test_df, tree):\n",
    "      predictions = test_df.apply(self.predict_example, args=(tree,), axis=1)\n",
    "      return predictions\n",
    "\n",
    "\n",
    "  ''' Method for making predictions ''' \n",
    "  def predict(self, test_df):\n",
    "    df_predictions = {}\n",
    "    df_predictions_probability = {}\n",
    "    for i in range(len(self.forest)):\n",
    "        column_name = \"tree_{}\".format(i)\n",
    "        predictions = self.decision_tree_predictions(test_df, tree=self.forest[i])\n",
    "\n",
    "        df_predictions[column_name] = predictions\n",
    "\n",
    "        if (self.ml_task == 'classification'):\n",
    "          probabilities = self.predict_proba(test_df, self.forest[i], self.each_tree_with_class_probabilities[i])\n",
    "          df_predictions_probability[column_name] = probabilities\n",
    "\n",
    "\n",
    "    df = pd.DataFrame(df_predictions)#.reset_index(drop = True)\n",
    "\n",
    "    if self.ml_task == 'classification':\n",
    "      df['Prediction'] = [df.iloc[j].mode()[0] for j in range(len(df))]\n",
    "      return df, self.final_probabilities(pd.DataFrame(df_predictions_probability))\n",
    "    else:\n",
    "      df['Prediction'] = [df.iloc[j].mean() for j in range(len(df))]    \n",
    "      return df\n",
    "\n",
    "\n",
    "  ''' making probability of the predictions using this tree '''\n",
    "  def predict_example_probability(self, example, tree):\n",
    "    question = list(tree.keys())[0]\n",
    "    feature_name, comparison_operator, value = question.split(\" \")[:3]\n",
    "\n",
    "    # ask question\n",
    "    if comparison_operator == \"<=\":\n",
    "        if example[feature_name] <= float(value):\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "    # feature is categorical\n",
    "    else:\n",
    "        if str(example[feature_name]) == value:\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "    # base case\n",
    "    if not isinstance(answer, dict):\n",
    "        return int(answer.split()[2])\n",
    "            \n",
    "    # recursive part\n",
    "    else:\n",
    "        residual_tree = answer\n",
    "        return self.predict_example_probability(example, residual_tree)\n",
    "\n",
    "\n",
    "  ''' This method returns the predicted probabilities for all classes '''\n",
    "  def predict_proba(self, X, complete_tree, leaf_node_class_proba):\n",
    "    leaf_nodes_for_predictions = np.array(X.apply(self.predict_example_probability, axis = 1, args = (complete_tree, )))\n",
    "    probabilities = [] \n",
    "    \n",
    "    \n",
    "    for i in leaf_nodes_for_predictions:\n",
    "      for key, value in leaf_node_class_proba.items():\n",
    "        if i == key:\n",
    "          probabilities.append(list(value))\n",
    "\n",
    "    return probabilities\n",
    "\n",
    "  def final_probabilities(self, df):\n",
    "    columns = df.columns.to_list()\n",
    "    values = []\n",
    "    for i in range(len(df)):\n",
    "      value = [0 for i in range(self.n_classes)]\n",
    "      row = df.iloc[i]\n",
    "      for j in columns:\n",
    "        value = [sum(x) for x in zip(value, row[j])]\n",
    "      value = [round(i/100, 5) for i in value]\n",
    "      values.append(value)\n",
    "    df['final_prob'] = values\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "NU0wLUFa3B8O"
   },
   "outputs": [],
   "source": [
    "forest = RandomForest(ml_task = 'classification', n_estimators = 100, n_bootstrap = 0.6, max_features=3, max_depth = 15, criterion = 'gini')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "BxXJjBWD3oRX",
    "outputId": "1e9db0de-c7ee-4b01-a91d-6a367c80c8ed"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Training completed'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "f0v-KEbW35R_"
   },
   "outputs": [],
   "source": [
    "preds, df_predictions_probability = forest.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "vxrY9fLHEp1J"
   },
   "outputs": [],
   "source": [
    "probabilities = [i for i in df_predictions_probability.values[:, -1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6vJmbOL5I9we",
    "outputId": "2139041f-46c8-4479-bfeb-d1338882ef8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0, 0.88, 0.12],\n",
       " [0.0, 0.0, 1.0],\n",
       " [0.0, 0.82, 0.18],\n",
       " [1.0, 0.0, 0.0],\n",
       " [1.0, 0.0, 0.0]]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probabilities[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ZuOuuo5EUwx",
    "outputId": "6046c2b2-efbc-4e09-e710-5271c5a09749"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score measured by one class versus rest classes is:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print('The AUC score measured by one class versus rest classes is: ',roc_auc_score(preds.values[:, -1],probabilities, multi_class = 'ovo'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C5fcC538Fu4h",
    "outputId": "9167372f-e590-40d0-d503-61c068c9e565"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.91        12\n",
      "           1       0.88      0.94      0.91        16\n",
      "           2       0.91      1.00      0.95        10\n",
      "\n",
      "    accuracy                           0.92        38\n",
      "   macro avg       0.93      0.92      0.92        38\n",
      "weighted avg       0.93      0.92      0.92        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test.values, preds.values[:, -1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6zm4JmeZ4UTu"
   },
   "source": [
    "# regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "qtLw2ARav_6b",
    "outputId": "5f2ed104-d9b1-4102-88f7-cdfeaac5076d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-6a946489-edb8-4ee7-b3ce-25bd625afde1\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>children</th>\n",
       "      <th>smoker</th>\n",
       "      <th>region</th>\n",
       "      <th>charges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>19</td>\n",
       "      <td>female</td>\n",
       "      <td>27.900</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>southwest</td>\n",
       "      <td>16884.92400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>male</td>\n",
       "      <td>33.770</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>1725.55230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>male</td>\n",
       "      <td>33.000</td>\n",
       "      <td>3</td>\n",
       "      <td>no</td>\n",
       "      <td>southeast</td>\n",
       "      <td>4449.46200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>33</td>\n",
       "      <td>male</td>\n",
       "      <td>22.705</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>21984.47061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>32</td>\n",
       "      <td>male</td>\n",
       "      <td>28.880</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "      <td>northwest</td>\n",
       "      <td>3866.85520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a946489-edb8-4ee7-b3ce-25bd625afde1')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-6a946489-edb8-4ee7-b3ce-25bd625afde1 button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-6a946489-edb8-4ee7-b3ce-25bd625afde1');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   age     sex     bmi  children smoker     region      charges\n",
       "0   19  female  27.900         0    yes  southwest  16884.92400\n",
       "1   18    male  33.770         1     no  southeast   1725.55230\n",
       "2   28    male  33.000         3     no  southeast   4449.46200\n",
       "3   33    male  22.705         0     no  northwest  21984.47061\n",
       "4   32    male  28.880         0     no  northwest   3866.85520"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/content/sample_data/insurance.csv')\n",
    "# df = df.drop(\"Id\", axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "bMGvt3Ou6XSl"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "lZ3vtdJF6bg3"
   },
   "outputs": [],
   "source": [
    "df['sex'] = encoder.fit_transform(df['sex'])\n",
    "df['smoker'] = encoder.fit_transform(df['smoker'])\n",
    "df['region'] = encoder.fit_transform(df['region'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "gUQrbezk6okQ"
   },
   "outputs": [],
   "source": [
    "X = df[df.columns.to_list()[:-1]]\n",
    "y = df['charges']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 42)#, test_size = 0.32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "bClvPu347pQP"
   },
   "outputs": [],
   "source": [
    "forest = RandomForest(ml_task = 'regression', n_estimators = 100, n_bootstrap = 0.6, max_features=3, max_depth = 10, criterion = 'mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "EvEdiav986TR",
    "outputId": "bc6487de-787b-4e36-ea5c-320b67120e95"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'Training completed'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "tQ50P5_c8-dh"
   },
   "outputs": [],
   "source": [
    "preds = forest.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ujEccB1MXGCj",
    "outputId": "5656d312-4d82-4a6b-b25f-6e8471e91a07"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2955.8851274534636"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "np.sqrt(mean_squared_error(y_train, preds.values[:, -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UO24eZJU6Sh6"
   },
   "outputs": [],
   "source": [
    "# tree = DescisionTree(max_depth = 3, criterion = 'mse', ml_task = 'regression', min_samples_leaf = 1, min_samples_split = 2, max_features = 6)\n",
    "# complete_tree = tree.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B0Lj-MxH6zHG",
    "outputId": "742a9c49-39a5-4208-bc97-9983b8afd4f8"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4609.576539446336"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "np.sqrt(mean_squared_error(y_test, forest.predict(X_test).values[:, -1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_nwy3tF4fSoI"
   },
   "source": [
    "# sklearn random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "4nS2io6GAz_7"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_jobs = -1, n_estimators = 100, max_features= 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fCyrOz8fBo7D",
    "outputId": "5aa03d36-cc51-4335-f1dc-d8a9b4a9e480"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_features=3, n_jobs=-1)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "b0SsOpdFBwgy",
    "outputId": "e9ca03ee-7aa5-42cd-c9a4-6445d7ff0e85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4598.288338378989"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test, rf.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b2M7I9Nfy73L"
   },
   "source": [
    "# backup tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3SwW4iqQB3Br"
   },
   "outputs": [],
   "source": [
    "# class DescisionTree:\n",
    "#   def __init__(self, min_samples_leaf, min_samples_split, max_depth, criterion, max_features, ml_task):\n",
    "#     self.data = None\n",
    "#     self.X = None\n",
    "#     self.y = None\n",
    "#     self.max_features = max_features\n",
    "#     self.ml_task = ml_task\n",
    "#     self.min_samples_leaf = min_samples_leaf\n",
    "#     self.min_samples_split = min_samples_split\n",
    "#     self.max_depth = max_depth\n",
    "#     self.metric = criterion\n",
    "#     self.feature_importances_ = None\n",
    "#     self.complete_tree = None\n",
    "#     self.n_entries = {}\n",
    "#     self.n_weighted_entries = {}\n",
    "#     self.parent_node = 1  # root node\n",
    "#     self.yes_node = 2     # left node\n",
    "#     self.no_node = 3      # right node\n",
    "#     self.leaf_count = 0\n",
    "#     if ml_task == 'classification': self.classes_and_counts = {};self.leaf_node_class_proba = {}\n",
    "#     else: self.leaf_node_loss = {}\n",
    "\n",
    "#   ''' This method is used to get the collective counts of all classes in target '''\n",
    "#   def get_classes_and_counts(self, data):\n",
    "#     label_column = data[:, -1]\n",
    "#     unique_classes, counts_unique_classes = np.unique(label_column, return_counts=True)\n",
    "#     for i in range(len(unique_classes)):\n",
    "#       self.classes_and_counts[unique_classes[i]] = counts_unique_classes[i]\n",
    "\n",
    "#   ''' This method is used to get the collective probabilities of all classes in target '''\n",
    "#   def get_probability_for_all_classes(self, data):\n",
    "#     label_column = data[:, -1]\n",
    "#     unique_classes_new, counts_unique_classes_new = np.unique(label_column, return_counts=True)\n",
    "    \n",
    "#     classes_and_counts_new = {}\n",
    "#     for i in list(self.classes_and_counts.keys()):\n",
    "#       if i in list(unique_classes_new):\n",
    "#         classes_and_counts_new[i] = counts_unique_classes_new[list(unique_classes_new).index(i)]\n",
    "#       else:\n",
    "#         classes_and_counts_new[i] = 0\n",
    "#     array = np.array(list(classes_and_counts_new.values())) / sum(classes_and_counts_new.values())\n",
    "\n",
    "#     return [round(i, 5) for i in array]\n",
    "\n",
    "\n",
    "#   ''' This method checks the purity of a target vector '''\n",
    "#   def check_purity(self, data):\n",
    "#       label_column = data[:, -1]\n",
    "#       unique_classes = np.unique(label_column)\n",
    "#       if len(unique_classes) == 1:\n",
    "#           return True\n",
    "#       else:\n",
    "#           return False\n",
    "\n",
    "\n",
    "#   ''' This method performs classification '''\n",
    "#   def create_leaf(self, data, ml_task, current_node):\n",
    "#       self.leaf_count += 1\n",
    "#       label_column = data[:, -1]\n",
    "#       if ml_task == \"regression\":\n",
    "#           leaf = np.mean(label_column)\n",
    "#           self.leaf_node_loss[current_node] = self.mse(data)\n",
    "#           return str(leaf) + ' Node: '+str(current_node)\n",
    "#       else:\n",
    "#           probabilities = []\n",
    "#           unique_classes, counts_unique_classes = np.unique(label_column, return_counts=True)\n",
    "#           index = counts_unique_classes.argmax()\n",
    "#           leaf = unique_classes[index]\n",
    "#           # probability = counts_unique_classes[index] / sum(counts_unique_classes)\n",
    "#           self.leaf_node_class_proba[current_node] = self.get_probability_for_all_classes(data)\n",
    "          \n",
    "#           return str(leaf) + ' Node: '+str(current_node)\n",
    "    \n",
    "    \n",
    "#   ''' this function generates all possible potential splits for a given training data '''\n",
    "#   def get_potential_splits(self, data, random_subspace):  # randomly selecting certain features\n",
    "#     potential_splits = {}\n",
    "#     _, n_columns = data.shape\n",
    "#     column_indices = list(range(n_columns - 1))    # excluding the last column which is the label\n",
    "#     if random_subspace and random_subspace <= len(column_indices):\n",
    "#         column_indices = random.sample(population=column_indices, k=random_subspace)\n",
    "#     for column_index in column_indices:          \n",
    "#         values = data[:, column_index]\n",
    "#         unique_values = np.unique(values)\n",
    "#         potential_splits[column_index] = unique_values\n",
    "\n",
    "#     return potential_splits\n",
    "    \n",
    "    \n",
    "#   ''' This function splits the data into two partitions: Yes and no cases'''\n",
    "#   def split_data(self, data, split_column, split_value):\n",
    "#       split_column_values = data[:, split_column]\n",
    "#       type_of_feature = FEATURE_TYPES[split_column]\n",
    "\n",
    "#       if type_of_feature == \"continuous\":\n",
    "#           data_below = data[split_column_values <= split_value]\n",
    "#           data_above = data[split_column_values >  split_value]\n",
    "#       else:\n",
    "#           data_below = data[split_column_values == split_value]\n",
    "#           data_above = data[split_column_values != split_value]\n",
    "      \n",
    "#       return data_below, data_above\n",
    "    \n",
    "    \n",
    "#   ''' This method calculates mse loss'''\n",
    "#   def mse(self, data):\n",
    "#       actual_values = data[:, -1]\n",
    "#       if len(actual_values) == 0:   # empty data\n",
    "#           mse = 0\n",
    "#       else:\n",
    "#           prediction = np.mean(actual_values)\n",
    "#           mse = np.mean((actual_values - prediction) **2)\n",
    "      \n",
    "#       return mse\n",
    "\n",
    "#   ''' This method calculates entropy loss '''\n",
    "#   def entropy(self, data):\n",
    "#       label_column = data[:, -1]\n",
    "#       _, counts = np.unique(label_column, return_counts=True)\n",
    "#       probabilities = counts / counts.sum()\n",
    "#       entropy = sum(probabilities * -np.log2(probabilities))\n",
    "      \n",
    "#       return entropy\n",
    "\n",
    "\n",
    "#   ''' This method calculates gini impurity'''\n",
    "#   def gini(self, data):\n",
    "#     label_column = data[:, -1]\n",
    "#     _, counts = np.unique(label_column, return_counts=True)\n",
    "#     probabilities = counts / counts.sum()\n",
    "#     gini_index = 0\n",
    "\n",
    "#     for i in probabilities:\n",
    "#       gini_index += i ** 2\n",
    "    \n",
    "#     return 1 - gini_index\n",
    "\n",
    "\n",
    "#   ''' calculating total/weighed value of the used metric '''\n",
    "#   def calculate_overall_metric(self, data_below, data_above, metric_function):\n",
    "#     n = len(data_below) + len(data_above)\n",
    "#     p_data_below = len(data_below) / n\n",
    "#     p_data_above = len(data_above) / n\n",
    "#     # weighted MSE, RMSE, Gini, and entropy\n",
    "#     overall_metric =  (p_data_below * metric_function(self, data_below) \n",
    "#                      + p_data_above * metric_function(self, data_above))\n",
    "    \n",
    "#     return overall_metric\n",
    "\n",
    "\n",
    "  \n",
    "#   ''' Determining which split is the best by using the metric '''\n",
    "#   def determine_best_split(self, data, potential_splits, ml_task, criterion):\n",
    "#     first_iteration = True\n",
    "#     for column_index in potential_splits:\n",
    "#         for value in potential_splits[column_index]:\n",
    "#             data_below, data_above = self.split_data(data, split_column=column_index, split_value=value)\n",
    "            \n",
    "        \n",
    "#             current_overall_metric = self.calculate_overall_metric(data_below, data_above, metric_function=criterion)\n",
    "#             if first_iteration or current_overall_metric <= best_overall_metric:\n",
    "#                 first_iteration = False\n",
    "#                 best_overall_metric = current_overall_metric\n",
    "#                 best_split_column = column_index\n",
    "#                 best_split_value = value\n",
    "    \n",
    "#     return best_split_column, best_split_value\n",
    "\n",
    "\n",
    "#   ''' determining the type of a feature among all features '''\n",
    "#   def determine_type_of_feature(self, df):\n",
    "#     feature_types = []\n",
    "#     n_unique_values_treshold = 10\n",
    "\n",
    "#     for feature in df.columns:\n",
    "#         if feature != \"label\":\n",
    "#             unique_values = df[feature].unique()\n",
    "#             example_value = unique_values[0]\n",
    "#             if (isinstance(example_value, str)) or (len(unique_values) <= n_unique_values_treshold):\n",
    "#                 feature_types.append(\"categorical\")\n",
    "#             else:\n",
    "#                 feature_types.append(\"continuous\")\n",
    "    \n",
    "#     return feature_types\n",
    " \n",
    "    \n",
    "#   ''' THIS IS THE MAIN RECURSIVE ALGORITHM FOR DESCISION TREE'''\n",
    "\n",
    "#   def tree(self, df, ml_task, counter,current_node, min_samples_leaf, min_samples_split,max_depth, criterion, answer, max_features):\n",
    "\n",
    "#     # When the tree starts, the dataframe is converteed to numpy array, the depth of the tree is checked using counter variable and all features types are detected\n",
    "#     if counter == 0:\n",
    "#         global COLUMN_HEADERS, FEATURE_TYPES\n",
    "#         COLUMN_HEADERS = df.columns\n",
    "#         FEATURE_TYPES = self.determine_type_of_feature(df)\n",
    "#         data = df.values\n",
    "#         criterion = getattr(DescisionTree, criterion)\n",
    "#     else:\n",
    "#         data = df      \n",
    "\n",
    "#     # storing the length of data passed into the node\n",
    "#     self.n_entries['Node: '+str(current_node)] = [len(df)]\n",
    "#     # criterion = getattr(DescisionTree, criterion)\n",
    "\n",
    "#     # storing the loss/mse/rmse/gini/entropy in a specific node\n",
    "#     self.n_entries['Node: '+str(current_node)].append(criterion(self, data))\n",
    "    \n",
    "#     # incrementing yes/left nodes and no/right nodes such that yes will be a even node and no will be a odd node repectively\n",
    "#     if (answer == 'yes answer'):\n",
    "#       self.yes_node += 2\n",
    "#     elif (answer == 'no answer'):\n",
    "#       self.no_node += 2 \n",
    "      \n",
    "#     # checking if that target of the data passed is either pure, has minimum samples to create a leaf, or the depth of tree has reached its maximum depth\n",
    "#     if (self.check_purity(data)) or (len(data) == min_samples_leaf) or (counter == max_depth):\n",
    "#         leaf = self.create_leaf(data, ml_task, current_node) # creating the leaf\n",
    "#         return leaf \n",
    "#     # if above requirements to create a leaf are not met, two new nodes will be created recursively respectively.\n",
    "#     else:    \n",
    "#         counter += 1 # when two new nodes are created, the depth of three is also incremented\n",
    "        \n",
    "#         # if the data is not yet pure, but has not minimum samples to perform the split, a leaf is created\n",
    "#         if (len(data) < min_samples_split):\n",
    "#           leaf = self.create_leaf(data, ml_task, current_node)\n",
    "#           return leaf\n",
    "#         else:\n",
    "#           # getting the all possible splits, determining which split has least loss, and splitting the data into left and right nodes respectively\n",
    "#           potential_splits = self.get_potential_splits(data, max_features)\n",
    "#           split_column, split_value = self.determine_best_split(data, potential_splits, ml_task,criterion)\n",
    "#           data_below, data_above = self.split_data(data, split_column, split_value)\n",
    "          \n",
    "#           # if the data seperated into left and right nodes, but there is no data, instead of creating a node, a leaft is created\n",
    "#           if len(data_below) == 0 or len(data_above) == 0:\n",
    "#               leaf = self.create_leaf(data, ml_task, current_node)\n",
    "#               return leaf\n",
    "          \n",
    "#           # finding the type of a selected feature column and its name\n",
    "#           feature_name = COLUMN_HEADERS[split_column]\n",
    "#           type_of_feature = FEATURE_TYPES[split_column]\n",
    "\n",
    "# #           # creating the tree questions\n",
    "#           if type_of_feature == \"continuous\":\n",
    "#               question = \"{} <= {} (Node: {})\".format(feature_name, split_value, current_node)\n",
    "#           # feature is categorical\n",
    "#           else:\n",
    "#               question = \"{} = {} (Node: {})\".format(feature_name, split_value, current_node)\n",
    "\n",
    "#           # instantiate sub-tree\n",
    "#           sub_tree = {question: []}\n",
    "\n",
    "#           # creating left and right nodes recursively\n",
    "#           yes_answer = self.tree(data_below, ml_task, counter, self.yes_node,min_samples_leaf, min_samples_split,max_depth, criterion, 'yes answer', max_features)\n",
    "#           no_answer = self.tree(data_above, ml_task, counter, self.no_node,min_samples_leaf,min_samples_split, max_depth, criterion, 'no answer', max_features)\n",
    "          \n",
    "#           # if both left and right nodes are same, only taking one value for a leaf node\n",
    "#           if yes_answer == no_answer:\n",
    "#               sub_tree = yes_answer\n",
    "#           else:\n",
    "#             sub_tree[question].append(yes_answer)\n",
    "#             sub_tree[question].append(no_answer)\n",
    "          \n",
    "#           return sub_tree\n",
    "\n",
    "    \n",
    "\n",
    "#   ''' making probability of the predictions using this tree '''\n",
    "#   def predict_example_probability(self, example, tree):\n",
    "#     question = list(tree.keys())[0]\n",
    "#     feature_name, comparison_operator, value = question.split(\" \")[:3]\n",
    "\n",
    "#     # ask question\n",
    "#     if comparison_operator == \"<=\":\n",
    "#         if example[feature_name] <= float(value):\n",
    "#             answer = tree[question][0]\n",
    "#         else:\n",
    "#             answer = tree[question][1]\n",
    "#     # feature is categorical\n",
    "#     else:\n",
    "#         if str(example[feature_name]) == value:\n",
    "#             answer = tree[question][0]\n",
    "#         else:\n",
    "#             answer = tree[question][1]\n",
    "#     # base case\n",
    "#     if not isinstance(answer, dict):\n",
    "#         return int(answer.split()[2])\n",
    "            \n",
    "#     # recursive part\n",
    "#     else:\n",
    "#         residual_tree = answer\n",
    "#         return self.predict_example_probability(example, residual_tree)\n",
    "\n",
    "    \n",
    "#   ''' fitting our tree with training data '''\n",
    "#   def fit(self, X,y):\n",
    "#     self.X = X.copy();self.y = y.copy()\n",
    "#     self.X['label'] = self.y;self.data = self.X\n",
    "\n",
    "#     if self.ml_task == 'classification':\n",
    "#       self.get_classes_and_counts(self.data.values)\n",
    "#     self.complete_tree = self.tree(self.data, self.ml_task, 0,self.parent_node, self.min_samples_leaf, self.min_samples_split, self.max_depth, self.metric,'parent_node', self.max_features)\n",
    "\n",
    "#     # calculating weighted entries\n",
    "#     for key, value in self.n_entries.items():\n",
    "#       self.n_weighted_entries[key] = [value[0] / len(self.X), value[1]]\n",
    "\n",
    "#     return self.complete_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LdynSoTpy94d"
   },
   "source": [
    "# Backup forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HVsxLTM7y9bc"
   },
   "outputs": [],
   "source": [
    "# class RandomForest:\n",
    "#   def __init__(self,criterion, n_estimators, n_bootstrap, ml_task, max_depth, max_features, min_samples_leaf = 1, min_samples_split = 2):\n",
    "#     self.n_estimators = n_estimators\n",
    "#     self.n_bootstrap = n_bootstrap\n",
    "#     self.max_features = max_features\n",
    "#     self.ml_task = ml_task\n",
    "#     self.min_samples_leaf = min_samples_leaf\n",
    "#     self.min_samples_split = min_samples_split\n",
    "#     self.max_depth = max_depth\n",
    "#     self.metric = criterion\n",
    "#     self.forest = []\n",
    "#     self.X = None\n",
    "#     self.y = None\n",
    "#     self.each_tree_with_class_probabilities = []\n",
    "#     self.n_classes = None\n",
    "\n",
    "\n",
    "\n",
    "#   ''' Performing boostraping '''\n",
    "#   def bootstrapping(self, X,y, n_bootstrap):\n",
    "#     bootstrap_indices = np.random.randint(low=0, high=len(X), size=int(n_bootstrap * len(X)))\n",
    "#     bootstraped_X = X.iloc[bootstrap_indices]\n",
    "#     bootstraped_y = y.iloc[bootstrap_indices]\n",
    "    \n",
    "#     return bootstraped_X, bootstraped_y\n",
    "\n",
    "\n",
    "#   ''' Training our model '''\n",
    "#   def fit(self, X, y):\n",
    "#     self.X = X.copy(); self.y = y.copy()\n",
    "#     self.n_classes = len(np.unique(self.y.values))\n",
    "#     for i in range(self.n_estimators):\n",
    "#       bootstraped_X, bootstraped_y= self.bootstrapping(self.X,self.y, self.n_bootstrap)\n",
    "#       tree = DescisionTree(min_samples_leaf = self.min_samples_leaf, min_samples_split = self.min_samples_split, max_depth =  self.max_depth, \\\n",
    "#                            criterion = self.metric, max_features = self.max_features, ml_task = self.ml_task)\n",
    "#       complete_tree = tree.fit(bootstraped_X, bootstraped_y)\n",
    "#       # getting probabilities for each class for individual classes\n",
    "#       if self.ml_task == 'classification':\n",
    "#         probabilities_of_each_nodes = tree.leaf_node_class_proba\n",
    "#         self.forest.append(complete_tree)\n",
    "#         self.each_tree_with_class_probabilities.append(probabilities_of_each_nodes)\n",
    "#       else:\n",
    "#         self.forest.append(complete_tree)\n",
    "    \n",
    "#     return 'Training completed'\n",
    "\n",
    "#   ''' Making individual predictions '''\n",
    "#   def predict_example(self, example, tree):\n",
    "#     question = list(tree.keys())[0]\n",
    "#     feature_name, comparison_operator, value = question.split(\" \")[:3]\n",
    "\n",
    "#     # ask question\n",
    "#     if comparison_operator == \"<=\":\n",
    "#         if example[feature_name] <= float(value):\n",
    "#             answer = tree[question][0]\n",
    "#         else:\n",
    "#             answer = tree[question][1]\n",
    "#     # feature is categorical\n",
    "#     else:\n",
    "#         if str(example[feature_name]) == value:\n",
    "#             answer = tree[question][0]\n",
    "#         else:\n",
    "#             answer = tree[question][1]\n",
    "#     # base case\n",
    "#     if not isinstance(answer, dict):\n",
    "#         return float(answer.split()[0])\n",
    "    \n",
    "#     # recursive part\n",
    "#     else:\n",
    "#         residual_tree = answer\n",
    "#         return self.predict_example(example, residual_tree)\n",
    "\n",
    "\n",
    "\n",
    "#   ''' Making predictions on testing dataframe '''\n",
    "#   def decision_tree_predictions(self, test_df, tree):\n",
    "#       predictions = test_df.apply(self.predict_example, args=(tree,), axis=1)\n",
    "#       return predictions\n",
    "\n",
    "\n",
    "#   ''' Method for making predictions ''' \n",
    "#   def predict(self, test_df):\n",
    "#     df_predictions = {}\n",
    "#     df_predictions_probability = {}\n",
    "#     for i in range(len(self.forest)):\n",
    "#         column_name = \"tree_{}\".format(i)\n",
    "#         predictions = self.decision_tree_predictions(test_df, tree=self.forest[i])\n",
    "\n",
    "#         df_predictions[column_name] = predictions\n",
    "\n",
    "#         if (self.ml_task == 'classification'):\n",
    "#           probabilities = self.predict_proba(test_df, self.forest[i], self.each_tree_with_class_probabilities[i])\n",
    "#           df_predictions_probability[column_name] = probabilities\n",
    "\n",
    "\n",
    "#     df = pd.DataFrame(df_predictions)#.reset_index(drop = True)\n",
    "\n",
    "#     if self.ml_task == 'classification':\n",
    "#       df['Prediction'] = [df.iloc[j].mode()[0] for j in range(len(df))]\n",
    "#       return df, self.final_probabilities(pd.DataFrame(df_predictions_probability))\n",
    "#     else:\n",
    "#       df['Prediction'] = [df.iloc[j].mean() for j in range(len(df))]    \n",
    "#       return df\n",
    "\n",
    "\n",
    "#   ''' making probability of the predictions using this tree '''\n",
    "#   def predict_example_probability(self, example, tree):\n",
    "#     question = list(tree.keys())[0]\n",
    "#     feature_name, comparison_operator, value = question.split(\" \")[:3]\n",
    "\n",
    "#     # ask question\n",
    "#     if comparison_operator == \"<=\":\n",
    "#         if example[feature_name] <= float(value):\n",
    "#             answer = tree[question][0]\n",
    "#         else:\n",
    "#             answer = tree[question][1]\n",
    "#     # feature is categorical\n",
    "#     else:\n",
    "#         if str(example[feature_name]) == value:\n",
    "#             answer = tree[question][0]\n",
    "#         else:\n",
    "#             answer = tree[question][1]\n",
    "#     # base case\n",
    "#     if not isinstance(answer, dict):\n",
    "#         return int(answer.split()[2])\n",
    "            \n",
    "#     # recursive part\n",
    "#     else:\n",
    "#         residual_tree = answer\n",
    "#         return self.predict_example_probability(example, residual_tree)\n",
    "\n",
    "\n",
    "#   ''' This method returns the predicted probabilities for all classes '''\n",
    "#   def predict_proba(self, X, complete_tree, leaf_node_class_proba):\n",
    "#     leaf_nodes_for_predictions = np.array(X.apply(self.predict_example_probability, axis = 1, args = (complete_tree, )))\n",
    "#     probabilities = [] \n",
    "    \n",
    "    \n",
    "#     for i in leaf_nodes_for_predictions:\n",
    "#       for key, value in leaf_node_class_proba.items():\n",
    "#         if i == key:\n",
    "#           probabilities.append(list(value))\n",
    "\n",
    "#     return probabilities\n",
    "\n",
    "#   def final_probabilities(self, df):\n",
    "#     columns = df.columns.to_list()\n",
    "#     values = []\n",
    "#     for i in range(len(df)):\n",
    "#       value = [0 for i in range(self.n_classes)]\n",
    "#       row = df.iloc[i]\n",
    "#       for j in columns:\n",
    "#         value = [sum(x) for x in zip(value, row[j])]\n",
    "#       value = [round(i/100, 5) for i in value]\n",
    "#       values.append(value)\n",
    "#     df['final_prob'] = values\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zDYq1NARzDhc"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "LdynSoTpy94d"
   ],
   "name": "RandomForest.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
