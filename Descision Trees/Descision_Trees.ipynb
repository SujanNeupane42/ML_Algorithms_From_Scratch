{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4Ii3rSxPWZPz"
   },
   "source": [
    "# Import Statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KGTOvmQeWPY9"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import random\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "7RieTioBWcQ7"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2Vh2dzf1Wf-q"
   },
   "source": [
    "# Load and prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-UKxz9QqWelC",
    "outputId": "5ac4c158-ba30-4342-a280-13a294b6bd07"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('day.csv', parse_dates=[\"dteday\"])\n",
    "df = df.drop([\"instant\", \"casual\", \"registered\"], axis=1)\n",
    "df = df.rename({\"dteday\": \"date\"}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>2012-12-27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.254167</td>\n",
       "      <td>0.226642</td>\n",
       "      <td>0.652917</td>\n",
       "      <td>0.350133</td>\n",
       "      <td>2114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>2012-12-28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.255046</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.155471</td>\n",
       "      <td>3095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>2012-12-29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.242400</td>\n",
       "      <td>0.752917</td>\n",
       "      <td>0.124383</td>\n",
       "      <td>1341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.255833</td>\n",
       "      <td>0.231700</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.350754</td>\n",
       "      <td>1796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.215833</td>\n",
       "      <td>0.223487</td>\n",
       "      <td>0.577500</td>\n",
       "      <td>0.154846</td>\n",
       "      <td>2729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>731 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  season  yr  mnth  holiday  weekday  workingday  weathersit  \\\n",
       "0   2011-01-01       1   0     1        0        6           0           2   \n",
       "1   2011-01-02       1   0     1        0        0           0           2   \n",
       "2   2011-01-03       1   0     1        0        1           1           1   \n",
       "3   2011-01-04       1   0     1        0        2           1           1   \n",
       "4   2011-01-05       1   0     1        0        3           1           1   \n",
       "..         ...     ...  ..   ...      ...      ...         ...         ...   \n",
       "726 2012-12-27       1   1    12        0        4           1           2   \n",
       "727 2012-12-28       1   1    12        0        5           1           2   \n",
       "728 2012-12-29       1   1    12        0        6           0           2   \n",
       "729 2012-12-30       1   1    12        0        0           0           1   \n",
       "730 2012-12-31       1   1    12        0        1           1           2   \n",
       "\n",
       "         temp     atemp       hum  windspeed   cnt  \n",
       "0    0.344167  0.363625  0.805833   0.160446   985  \n",
       "1    0.363478  0.353739  0.696087   0.248539   801  \n",
       "2    0.196364  0.189405  0.437273   0.248309  1349  \n",
       "3    0.200000  0.212122  0.590435   0.160296  1562  \n",
       "4    0.226957  0.229270  0.436957   0.186900  1600  \n",
       "..        ...       ...       ...        ...   ...  \n",
       "726  0.254167  0.226642  0.652917   0.350133  2114  \n",
       "727  0.253333  0.255046  0.590000   0.155471  3095  \n",
       "728  0.253333  0.242400  0.752917   0.124383  1341  \n",
       "729  0.255833  0.231700  0.483333   0.350754  1796  \n",
       "730  0.215833  0.223487  0.577500   0.154846  2729  \n",
       "\n",
       "[731 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-5-7f76abfc0f02>:7: FutureWarning: Series.dt.weekofyear and Series.dt.week have been deprecated. Please use Series.dt.isocalendar().week instead.\n",
      "  df[\"week\"] = date_column.dt.week\n"
     ]
    }
   ],
   "source": [
    "date_column = df.date\n",
    "\n",
    "df[\"day_of_year\"] = date_column.dt.dayofyear\n",
    "df[\"day_of_month\"] = date_column.dt.day\n",
    "\n",
    "df[\"quarter\"] = date_column.dt.quarter\n",
    "df[\"week\"] = date_column.dt.week\n",
    "\n",
    "df[\"is_month_end\"] = date_column.dt.is_month_end\n",
    "df[\"is_month_start\"] = date_column.dt.is_month_start\n",
    "df[\"is_quarter_end\"] = date_column.dt.is_quarter_end\n",
    "df[\"is_quarter_start\"] = date_column.dt.is_quarter_start\n",
    "df[\"is_year_end\"] = date_column.dt.is_year_end\n",
    "df[\"is_year_start\"] = date_column.dt.is_year_start\n",
    "\n",
    "df = df.set_index(\"date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label\"] = df.cnt\n",
    "df = df.drop(\"cnt\", axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = df.iloc[:-61]\n",
    "test_df = df.iloc[-61:]     # Nov and Dec of 2012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import LabelEncoder\n",
    "# encoder = LabelEncoder()\n",
    "\n",
    "# df['sex'] = encoder.fit_transform(df['sex'])\n",
    "# df['smoker'] = encoder.fit_transform(df['smoker'])\n",
    "# df['region'] = encoder.fit_transform(df['region'])\n",
    "\n",
    "# X = df[df.columns.to_list()[:-1]]\n",
    "# y = df['charges']\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 121)#, test_size = 0.32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('insurance.csv')\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "df['sex'] = encoder.fit_transform(df['sex'])\n",
    "df['smoker'] = encoder.fit_transform(df['smoker'])\n",
    "df['region'] = encoder.fit_transform(df['region'])\n",
    "X = df[df.columns.to_list()[:-1]]\n",
    "y = df['charges']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 121)#, test_size = 0.32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4457.0472994953025"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DescisionTree(max_depth = 3, criterion = 'mse', ml_task = 'regression')\n",
    "complete_tree = tree.fit(X_train, y_train) \n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "np.sqrt(mean_squared_error(y_train, tree.predict(X_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5101.821731158357"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "np.sqrt(mean_squared_error(y_test, tree.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'smoker = 1.0 (Node: 1)': [{'bmi <= 30.0 (Node: 2)': [{'age <= 39.0 (Node: 4)': ['18640.563641296296 Node: 6',\n",
       "      '25857.196740975614 Node: 3']},\n",
       "    {'age <= 30.0 (Node: 5)': ['36882.46957657896 Node: 8',\n",
       "      '44431.574282318834 Node: 7']}]},\n",
       "  {'age <= 44.0 (Node: 9)': [{'children = 0.0 (Node: 10)': ['3888.112809062176 Node: 12',\n",
       "      '6642.901125830388 Node: 11']},\n",
       "    {'age <= 51.0 (Node: 13)': ['10295.298627016131 Node: 14',\n",
       "      '13809.460579850747 Node: 15']}]}]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vq8RghH-mmaf"
   },
   "source": [
    "# Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BT-v4WL-mmF4"
   },
   "outputs": [],
   "source": [
    "class DescisionTree:\n",
    "  def __init__(self, criterion,ml_task = 'classification', min_samples_leaf=1, min_samples_split = 2, max_depth = 5):\n",
    "    self.data = None\n",
    "    self.X = None\n",
    "    self.y = None\n",
    "    self.ml_task = ml_task\n",
    "    self.min_samples_leaf = min_samples_leaf\n",
    "    self.min_samples_split = min_samples_split\n",
    "    self.max_depth = max_depth\n",
    "    self.metric = criterion\n",
    "    self.feature_importances_ = None\n",
    "    self.complete_tree = None\n",
    "    self.n_entries = {}\n",
    "    self.n_weighted_entries = {}\n",
    "    self.parent_node = 1  # root node\n",
    "    self.yes_node = 2     # left node\n",
    "    self.no_node = 3      # right node\n",
    "    self.leaf_count = 0\n",
    "    if ml_task == 'classification': self.classes_and_counts = {};self.leaf_node_class_proba = {}\n",
    "    else: self.leaf_node_loss = {}\n",
    "    \n",
    "\n",
    "  ''' This method is used to get the collective counts of all classes in target '''\n",
    "  def get_classes_and_counts(self, data):\n",
    "    label_column = data[:, -1]\n",
    "    unique_classes, counts_unique_classes = np.unique(label_column, return_counts=True)\n",
    "    for i in range(len(unique_classes)):\n",
    "      self.classes_and_counts[unique_classes[i]] = counts_unique_classes[i]\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "  ''' This method is used to get the collective probabilities of all classes in target '''\n",
    "  def get_probability_for_all_classes(self, data):\n",
    "    label_column = data[:, -1]\n",
    "    unique_classes_new, counts_unique_classes_new = np.unique(label_column, return_counts=True)\n",
    "    \n",
    "    classes_and_counts_new = {}\n",
    "    for i in list(self.classes_and_counts.keys()):\n",
    "      if i in list(unique_classes_new):\n",
    "        classes_and_counts_new[i] = counts_unique_classes_new[list(unique_classes_new).index(i)]\n",
    "      else:\n",
    "        classes_and_counts_new[i] = 0\n",
    "    array = np.array(list(classes_and_counts_new.values())) / sum(classes_and_counts_new.values())\n",
    "\n",
    "    return [round(i, 5) for i in array]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  ''' This method checks the purity of a target vector '''\n",
    "  def check_purity(self, data):\n",
    "      label_column = data[:, -1]\n",
    "      unique_classes = np.unique(label_column)\n",
    "      if len(unique_classes) == 1:\n",
    "          return True\n",
    "      else:\n",
    "          return False\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "  ''' This method performs classification '''\n",
    "  def create_leaf(self, data, ml_task, current_node):\n",
    "      self.leaf_count += 1\n",
    "      label_column = data[:, -1]\n",
    "      if ml_task == \"regression\":\n",
    "          leaf = np.mean(label_column)\n",
    "          self.leaf_node_loss[current_node] = self.mse(data)\n",
    "          return str(leaf) + ' Node: '+str(current_node)\n",
    "      else:\n",
    "          probabilities = []\n",
    "          unique_classes, counts_unique_classes = np.unique(label_column, return_counts=True)\n",
    "          index = counts_unique_classes.argmax()\n",
    "          leaf = unique_classes[index]\n",
    "          # probability = counts_unique_classes[index] / sum(counts_unique_classes)\n",
    "          self.leaf_node_class_proba[current_node] = self.get_probability_for_all_classes(data)\n",
    "          \n",
    "          return str(leaf) + ' Node: '+str(current_node)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "  ''' this function generates all possible potential splits for a given training data '''\n",
    "  def get_potential_splits(self, data):\n",
    "      potential_splits = {}\n",
    "      _, n_columns = data.shape\n",
    "      for column_index in range(n_columns - 1):   \n",
    "          values = data[:, column_index]\n",
    "          unique_values = np.unique(values)\n",
    "          potential_splits[column_index] = unique_values\n",
    "      \n",
    "      return potential_splits\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "  ''' This function splits the data into two partitions: Yes and no cases'''\n",
    "  def split_data(self, data, split_column, split_value):\n",
    "      split_column_values = data[:, split_column]\n",
    "      type_of_feature = FEATURE_TYPES[split_column]\n",
    "\n",
    "      if type_of_feature == \"continuous\":\n",
    "          data_below = data[split_column_values <= split_value]\n",
    "          data_above = data[split_column_values >  split_value]\n",
    "      else:\n",
    "          data_below = data[split_column_values == split_value]\n",
    "          data_above = data[split_column_values != split_value]\n",
    "      \n",
    "      return data_below, data_above\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "  ''' This method calculates mse loss'''\n",
    "  def mse(self, data):\n",
    "      actual_values = data[:, -1]\n",
    "      if len(actual_values) == 0:   # empty data\n",
    "          mse = 0\n",
    "      else:\n",
    "          prediction = np.mean(actual_values)\n",
    "          mse = np.mean((actual_values - prediction) **2)\n",
    "      \n",
    "      return mse\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "  ''' This method calculates entropy loss '''\n",
    "  def entropy(self, data):\n",
    "      label_column = data[:, -1]\n",
    "      _, counts = np.unique(label_column, return_counts=True)\n",
    "      probabilities = counts / counts.sum()\n",
    "      entropy = sum(probabilities * -np.log2(probabilities))\n",
    "      \n",
    "      return entropy\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "  ''' This method calculates gini impurity'''\n",
    "  def gini(self, data):\n",
    "    label_column = data[:, -1]\n",
    "    _, counts = np.unique(label_column, return_counts=True)\n",
    "    probabilities = counts / counts.sum()\n",
    "    gini_index = 0\n",
    "\n",
    "    for i in probabilities:\n",
    "      gini_index += i ** 2\n",
    "    \n",
    "    return 1 - gini_index\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  ''' calculating total/weighed value of the used metric '''\n",
    "  def calculate_overall_metric(self, data_below, data_above, metric_function):\n",
    "    n = len(data_below) + len(data_above)\n",
    "    p_data_below = len(data_below) / n\n",
    "    p_data_above = len(data_above) / n\n",
    "    # weighted MSE, RMSE, Gini, and entropy\n",
    "    overall_metric =  (p_data_below * metric_function(self, data_below) \n",
    "                     + p_data_above * metric_function(self, data_above))\n",
    "    \n",
    "    return overall_metric\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "  ''' Determining which split is the best by using the metric '''\n",
    "  def determine_best_split(self, data, potential_splits, ml_task, criterion):\n",
    "    first_iteration = True\n",
    "    for column_index in potential_splits:\n",
    "        for value in potential_splits[column_index]:\n",
    "            data_below, data_above = self.split_data(data, split_column=column_index, split_value=value)\n",
    "            \n",
    "        \n",
    "            current_overall_metric = self.calculate_overall_metric(data_below, data_above, metric_function=criterion)\n",
    "            if first_iteration or current_overall_metric <= best_overall_metric:\n",
    "                first_iteration = False\n",
    "                best_overall_metric = current_overall_metric\n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "    \n",
    "    return best_split_column, best_split_value\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  ''' determining the type of a feature among all features '''\n",
    "  def determine_type_of_feature(self, df):\n",
    "    feature_types = []\n",
    "    n_unique_values_treshold = 10\n",
    "\n",
    "    for feature in df.columns:\n",
    "        if feature != \"label\":\n",
    "            unique_values = df[feature].unique()\n",
    "            example_value = unique_values[0]\n",
    "            if (isinstance(example_value, str)) or (len(unique_values) <= n_unique_values_treshold):\n",
    "                feature_types.append(\"categorical\")\n",
    "            else:\n",
    "                feature_types.append(\"continuous\")\n",
    "    \n",
    "    return feature_types\n",
    "\n",
    "  \n",
    "    \n",
    "    \n",
    "    \n",
    "  ''' THIS IS THE MAIN RECURSIVE ALGORITHM FOR DESCISION TREE'''\n",
    "  def tree(self, df, ml_task, counter,current_node, min_samples_leaf, min_samples_split,max_depth, criterion, answer):\n",
    "\n",
    "    # When the tree starts, the dataframe is converteed to numpy array, the depth of the tree is checked using counter variable and all features types are detected\n",
    "    if counter == 0:\n",
    "        global COLUMN_HEADERS, FEATURE_TYPES\n",
    "        COLUMN_HEADERS = df.columns\n",
    "        FEATURE_TYPES = self.determine_type_of_feature(df)\n",
    "        data = df.values\n",
    "        criterion = getattr(DescisionTree, criterion)\n",
    "    else:\n",
    "        data = df      \n",
    "\n",
    "    # storing the length of data passed into the node\n",
    "    self.n_entries['Node: '+str(current_node)] = [len(df)]\n",
    "    # criterion = getattr(DescisionTree, criterion)\n",
    "\n",
    "    # storing the loss/mse/rmse/gini/entropy in a specific node\n",
    "    self.n_entries['Node: '+str(current_node)].append(criterion(self, data))\n",
    "    \n",
    "    # incrementing yes/left nodes and no/right nodes such that yes will be a even node and no will be a odd node repectively\n",
    "    if (answer == 'yes answer'):\n",
    "      self.yes_node += 2\n",
    "    elif (answer == 'no answer'):\n",
    "      self.no_node += 2 \n",
    "      \n",
    "    # checking if that target of the data passed is either pure, has minimum samples to create a leaf, or the depth of tree has reached its maximum depth\n",
    "    if (self.check_purity(data)) or (len(data) == min_samples_leaf) or (counter == max_depth):\n",
    "        leaf = self.create_leaf(data, ml_task, current_node) # creating the leaf\n",
    "        return leaf \n",
    "    # if above requirements to create a leaf are not met, two new nodes will be created recursively respectively.\n",
    "    else:    \n",
    "        counter += 1 # when two new nodes are created, the depth of three is also incremented\n",
    "        \n",
    "        # if the data is not yet pure, but has not minimum samples to perform the split, a leaf is created\n",
    "        if (len(data) < min_samples_split):\n",
    "          leaf = self.create_leaf(data, ml_task, current_node)\n",
    "          return leaf\n",
    "        else:\n",
    "          # getting the all possible splits, determining which split has least loss, and splitting the data into left and right nodes respectively\n",
    "          potential_splits = self.get_potential_splits(data)\n",
    "          split_column, split_value = self.determine_best_split(data, potential_splits, ml_task,criterion)\n",
    "          data_below, data_above = self.split_data(data, split_column, split_value)\n",
    "          \n",
    "          # if the data seperated into left and right nodes, but there is no data, instead of creating a node, a leaft is created\n",
    "          if len(data_below) == 0 or len(data_above) == 0:\n",
    "              leaf = self.create_leaf(data, ml_task, current_node)\n",
    "              return leaf\n",
    "          \n",
    "          # finding the type of a selected feature column and its name\n",
    "          feature_name = COLUMN_HEADERS[split_column]\n",
    "          type_of_feature = FEATURE_TYPES[split_column]\n",
    "\n",
    "#           # creating the tree questions\n",
    "          if type_of_feature == \"continuous\":\n",
    "              question = \"{} <= {} (Node: {})\".format(feature_name, split_value, current_node)\n",
    "          # feature is categorical\n",
    "          else:\n",
    "              question = \"{} = {} (Node: {})\".format(feature_name, split_value, current_node)\n",
    "\n",
    "          # instantiate sub-tree\n",
    "          sub_tree = {question: []}\n",
    "\n",
    "          # creating left and right nodes recursively\n",
    "          yes_answer = self.tree(data_below, ml_task, counter, self.yes_node,min_samples_leaf, min_samples_split,max_depth, criterion, 'yes answer')\n",
    "          no_answer = self.tree(data_above, ml_task, counter, self.no_node,min_samples_leaf,min_samples_split, max_depth, criterion, 'no answer')\n",
    "          \n",
    "          # if both left and right nodes are same, only taking one value for a leaf node\n",
    "          if yes_answer == no_answer:\n",
    "              sub_tree = yes_answer\n",
    "          else:\n",
    "            sub_tree[question].append(yes_answer)\n",
    "            sub_tree[question].append(no_answer)\n",
    "          \n",
    "          return sub_tree\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "  ''' making predictions using this tree '''\n",
    "  def predict_example(self, example, tree):\n",
    "    question = list(tree.keys())[0]\n",
    "    feature_name, comparison_operator, value = question.split(\" \")[:3]\n",
    "\n",
    "    # ask question\n",
    "    if comparison_operator == \"<=\":\n",
    "        if example[feature_name] <= float(value):\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "    # feature is categorical\n",
    "    else:\n",
    "        if str(example[feature_name]) == value:\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "    # base case\n",
    "    if not isinstance(answer, dict):\n",
    "        return float(answer.split()[0])\n",
    "    \n",
    "    # recursive part\n",
    "    else:\n",
    "        residual_tree = answer\n",
    "        return self.predict_example(example, residual_tree)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "  ''' making probability of the predictions using this tree '''\n",
    "  def predict_example_probability(self, example, tree):\n",
    "    question = list(tree.keys())[0]\n",
    "    feature_name, comparison_operator, value = question.split(\" \")[:3]\n",
    "\n",
    "    # ask question\n",
    "    if comparison_operator == \"<=\":\n",
    "        if example[feature_name] <= float(value):\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "    # feature is categorical\n",
    "    else:\n",
    "        if str(example[feature_name]) == value:\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "    # base case\n",
    "    if not isinstance(answer, dict):\n",
    "        return int(answer.split()[2])\n",
    "            \n",
    "    # recursive part\n",
    "    else:\n",
    "        residual_tree = answer\n",
    "        return self.predict_example_probability(example, residual_tree)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "  ''' fitting our tree with training data '''\n",
    "  def fit(self, X,y):\n",
    "    self.X = X.copy();self.y = y.copy()\n",
    "    self.X['label'] = self.y;self.data = self.X\n",
    "\n",
    "    if self.ml_task == 'classification':\n",
    "      self.get_classes_and_counts(self.data.values)\n",
    "    self.complete_tree = self.tree(self.data, self.ml_task, 0,self.parent_node, self.min_samples_leaf, self.min_samples_split, self.max_depth, self.metric,'parent_node')\n",
    "\n",
    "    # calculating weighted entries\n",
    "    for key, value in self.n_entries.items():\n",
    "      self.n_weighted_entries[key] = [value[0] / len(self.X), value[1]]\n",
    "\n",
    "    return self.complete_tree\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  ''' Making predictions '''\n",
    "  def predict(self, X):\n",
    "    # X_train.apply(predict_example, axis=1, args=(tree_gini,))\n",
    "    predictions = np.array(X.apply(self.predict_example, axis = 1, args = (self.complete_tree, )))\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  ''' This method returns the predicted probabilities for all classes '''\n",
    "  def predict_proba(self, X):\n",
    "    leaf_nodes_for_predictions = np.array(X.apply(self.predict_example_probability, axis = 1, args = (self.complete_tree, )))\n",
    "    probabilities = [] \n",
    "    \n",
    "    \n",
    "    for i in leaf_nodes_for_predictions:\n",
    "      for key, value in self.leaf_node_class_proba.items():\n",
    "        if i == key:\n",
    "          probabilities.append(list(value))\n",
    "\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train_df[train_df.columns.to_list()[:-1]]\n",
    "y = train_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df[test_df.columns.to_list()[:-1]]\n",
    "y_test = test_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DescisionTree(max_depth = 3, criterion = 'mse', ml_task = 'regression')\n",
    "complete_tree = tree.fit(X, y) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'temp <= 0.430833 (Node: 1)': [{'yr = 1 (Node: 2)': [{'atemp <= 0.309909 (Node: 4)': ['2938.175 Node: 6',\n",
       "      '4316.7441860465115 Node: 3']},\n",
       "    {'season = 4 (Node: 5)': ['3364.734693877551 Node: 8',\n",
       "      '1711.138888888889 Node: 7']}]},\n",
       "  {'yr = 1 (Node: 9)': [{'hum <= 0.83125 (Node: 10)': ['6735.924528301887 Node: 12',\n",
       "      '4203.6 Node: 11']},\n",
       "    {'weathersit = 3 (Node: 13)': ['2320.5 Node: 14', '4374.32 Node: 15']}]}]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "848.5977169927768"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "np.sqrt(mean_squared_error(y, tree.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1470.923070804387"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "np.sqrt(mean_squared_error(y_test, tree.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.  mse garauda kei vaena.. self.mse implement garda\n",
    "# 2. create leaf ra predit example purai change gare.. additionally, tree ko algorithm bhitra tree string banaune\n",
    "#    string ni change gae------------ yes\n",
    "\n",
    "\n",
    "# 3. undo previous changes that did not change any model's performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_search = {\"max_depth\": [], \"min_samples\": [], \"r_squared_train\": [], \"r_squared_val\": []}\n",
    "# for max_depth in range(1, 7):\n",
    "#     for min_samples in range(5, 20, 5):\n",
    "#         tree = DescisionTree(max_depth = max_depth, criterion = 'mse', ml_task = 'regression', min_samples_leaf = min_samples)\n",
    "#         complete_tree = tree.fit(X, y) \n",
    "# #         tree = DescisionTree(train_df, ml_task=\"regression\", max_depth=max_depth, min_samples=min_samples, criterion = 'mse')\n",
    "        \n",
    "#         r_squared_train = calculate_r_squared(train_df, complete_tree)\n",
    "#         r_squared_val = calculate_r_squared(test_df, complete_tree)\n",
    "        \n",
    "#         grid_search[\"max_depth\"].append(max_depth)\n",
    "#         grid_search[\"min_samples\"].append(min_samples)\n",
    "#         grid_search[\"r_squared_train\"].append(r_squared_train)\n",
    "#         grid_search[\"r_squared_val\"].append(r_squared_val)\n",
    "        \n",
    "#     print(f\"Progress: Iteration {max_depth}/6\")\n",
    "        \n",
    "# grid_search = pd.DataFrame(grid_search)\n",
    "# grid_search.sort_values(\"r_squared_val\", ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('iris.csv')\n",
    "X = df[df.columns.to_list()[:-1]]\n",
    "y = df['Species']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = 121)#, test_size = 0.32\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y_train)\n",
    "\n",
    "y_train = encoder.transform(y_train)\n",
    "y_test = encoder.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = DescisionTree(max_depth = 5, criterion = 'gini', ml_task = 'classification')\n",
    "complete_tree = tree.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.83      0.91        12\n",
      "           1       0.89      1.00      0.94        16\n",
      "           2       1.00      1.00      1.00        10\n",
      "\n",
      "    accuracy                           0.95        38\n",
      "   macro avg       0.96      0.94      0.95        38\n",
      "weighted avg       0.95      0.95      0.95        38\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, tree.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4: [1.0, 0.0, 0.0], 3: [0.0, 1.0, 0.0], 5: [0.0, 0.0, 1.0]}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.leaf_node_class_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Id <= 100.0 (Node: 1)': [{'PetalWidthCm <= 0.4 (Node: 2)': ['0.0 Node: 4',\n",
       "    '1.0 Node: 3']},\n",
       "  '2.0 Node: 5']}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "complete_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Tree_1': [[0.0, 1.0, 0.0],\n",
       "  [0.0, 0.0, 1.0],\n",
       "  [0.0, 1.0, 0.0],\n",
       "  [1.0, 0.0, 0.0],\n",
       "  [1.0, 0.0, 0.0],\n",
       "  [0.0, 1.0, 0.0],\n",
       "  [0.0, 1.0, 0.0],\n",
       "  [0.0, 1.0, 0.0],\n",
       "  [0.0, 1.0, 0.0],\n",
       "  [0.0, 0.0, 1.0],\n",
       "  [0.0, 1.0, 0.0],\n",
       "  [0.0, 1.0, 0.0],\n",
       "  [0.0, 1.0, 0.0],\n",
       "  [1.0, 0.0, 0.0],\n",
       "  [1.0, 0.0, 0.0],\n",
       "  [0.0, 0.0, 1.0],\n",
       "  [0.0, 1.0, 0.0],\n",
       "  [1.0, 0.0, 0.0],\n",
       "  [0.0, 0.0, 1.0],\n",
       "  [1.0, 0.0, 0.0],\n",
       "  [0.0, 0.0, 1.0],\n",
       "  [0.0, 0.0, 1.0],\n",
       "  [0.0, 1.0, 0.0],\n",
       "  [0.0, 1.0, 0.0],\n",
       "  [0.0, 1.0, 0.0],\n",
       "  [0.0, 1.0, 0.0],\n",
       "  [1.0, 0.0, 0.0],\n",
       "  [0.0, 1.0, 0.0],\n",
       "  [0.0, 0.0, 1.0],\n",
       "  [0.0, 0.0, 1.0],\n",
       "  [0.0, 1.0, 0.0],\n",
       "  [0.0, 0.0, 1.0],\n",
       "  [1.0, 0.0, 0.0],\n",
       "  [0.0, 1.0, 0.0],\n",
       "  [0.0, 1.0, 0.0],\n",
       "  [0.0, 0.0, 1.0],\n",
       "  [1.0, 0.0, 0.0],\n",
       "  [1.0, 0.0, 0.0]]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'Tree_1':tree.predict_proba(X_test)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=3)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sklearn tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "tree_ = DecisionTreeRegressor(max_depth = 3, max_features = None)\n",
    "tree_.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1470.923070804387"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sqrt(mean_squared_error(y_test, tree_.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Uj_CNKH7zSBz"
   },
   "outputs": [],
   "source": [
    "tree = DescisionTree(max_depth = 3, criterion = 'entropy')\n",
    "complete_tree = tree.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fJ3EDQXMGGnK",
    "outputId": "5919d524-1c98-4402-e7c3-0f3f2c5f5804"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2: [1.0, 0.0, 0.0],\n",
       " 5: [0.0, 0.33333, 0.66667],\n",
       " 6: [0.0, 0.9697, 0.0303],\n",
       " 7: [0.0, 0.0, 1.0]}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree.leaf_node_class_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K3jVmK3k4xpH",
    "outputId": "6d9675b0-36ad-42b4-be5a-edd27d97fa79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PetalWidthCm <= 0.4 (Node: 1)': ['0.0 '\n",
      "                                   'Node: '\n",
      "                                   '2',\n",
      "                                   {'PetalWidthCm <= 1.7 (Node: 3)': [{'PetalLengthCm <= 4.9 (Node: 4)': ['1.0 '\n",
      "                                                                                                          'Node: '\n",
      "                                                                                                          '6',\n",
      "                                                                                                          '2.0 '\n",
      "                                                                                                          'Node: '\n",
      "                                                                                                          '5']},\n",
      "                                                                      '2.0 '\n",
      "                                                                      'Node: '\n",
      "                                                                      '7']}]}\n"
     ]
    }
   ],
   "source": [
    "pprint(complete_tree, width = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P6FrCPYq8Tof"
   },
   "outputs": [],
   "source": [
    "test_predictions = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FDPVgPte_-bE",
    "outputId": "eca27bba-3484-4019-f6e9-11ee090af603"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6 7 6 2 2 6 6 6 6 7 7 6 6 2 2 7 6 2 7 2 7 7 6 6 6 6 2 6 7 7 6 7 2 6 6 7 2\n",
      " 2]\n"
     ]
    }
   ],
   "source": [
    "test_predictions_proba = tree.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WxZQmLxABku1",
    "outputId": "5b7f4889-2e75-4858-b0ba-eff5ec7649cc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The AUC score measured by one class versus rest classes is:  1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print('The AUC score measured by one class versus rest classes is: ',roc_auc_score(test_predictions, test_predictions_proba, multi_class = 'ovo'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FbP9LuAwXv6q"
   },
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-I9mEIQxaJb6"
   },
   "source": [
    "## Data pure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HJVrNWVzXp2i"
   },
   "outputs": [],
   "source": [
    "''' This function checks the purity of a target vector '''\n",
    "\n",
    "def check_purity(data):\n",
    "    \n",
    "    label_column = data[:, -1]\n",
    "    unique_classes = np.unique(label_column)\n",
    "\n",
    "    if len(unique_classes) == 1:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-wDL4MWaF2p"
   },
   "source": [
    "## Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7PvS-Dj4Z55B"
   },
   "outputs": [],
   "source": [
    "''' This function performs classification '''\n",
    "\n",
    "def create_leaf(data, ml_task):\n",
    "    \n",
    "    label_column = data[:, -1]\n",
    "    if ml_task == \"regression\":\n",
    "        leaf = np.mean(label_column)\n",
    "        \n",
    "    # classfication    \n",
    "    else:\n",
    "        unique_classes, counts_unique_classes = np.unique(label_column, return_counts=True)\n",
    "        index = counts_unique_classes.argmax()\n",
    "        leaf = unique_classes[index]\n",
    "        \n",
    "\n",
    "    return leaf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhJl_GJAbCKS"
   },
   "source": [
    "## Potential splits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ch6FClRtalNh"
   },
   "outputs": [],
   "source": [
    "''' this function generates all possible potential splits for a given training data '''\n",
    "\n",
    "def get_potential_splits(data):\n",
    "    \n",
    "    potential_splits = {}\n",
    "    _, n_columns = data.shape\n",
    "    for column_index in range(n_columns - 1):          # excluding the last column which is the label\n",
    "        values = data[:, column_index]\n",
    "        unique_values = np.unique(values)\n",
    "\n",
    "        potential_splits[column_index] = unique_values\n",
    "        \n",
    "        # type_of_feature = FEATURE_TYPES[column_index]\n",
    "        # if type_of_feature == \"continuous\":\n",
    "        #     potential_splits[column_index] = []\n",
    "        #     for index in range(len(unique_values)):\n",
    "        #         if index != 0:\n",
    "        #             current_value = unique_values[index]\n",
    "        #             previous_value = unique_values[index - 1]\n",
    "        #             potential_split = (current_value + previous_value) / 2\n",
    "\n",
    "        #             potential_splits[column_index].append(potential_split)\n",
    "        \n",
    "        # # feature is categorical\n",
    "        # # (there need to be at least 2 unique values, otherwise in the\n",
    "        # # split_data function data_below would contain all data points\n",
    "        # # and data_above would be empty)\n",
    "        # elif len(unique_values) > 1:\n",
    "        #     potential_splits[column_index] = unique_values\n",
    "    \n",
    "    return potential_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OsXyqjwOcZmh"
   },
   "source": [
    "## Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DBDYXPJjbrQZ"
   },
   "outputs": [],
   "source": [
    "''' This function splits the data into two partitions: Yes and no cases'''\n",
    "\n",
    "def split_data(data, split_column, split_value):\n",
    "    \n",
    "    split_column_values = data[:, split_column]\n",
    "\n",
    "    type_of_feature = FEATURE_TYPES[split_column]\n",
    "    if type_of_feature == \"continuous\":\n",
    "        data_below = data[split_column_values <= split_value]\n",
    "        data_above = data[split_column_values >  split_value]\n",
    "    \n",
    "    # feature is categorical   \n",
    "    else:\n",
    "        data_below = data[split_column_values == split_value]\n",
    "        data_above = data[split_column_values != split_value]\n",
    "    \n",
    "    return data_below, data_above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7YnwrbWPc3EI"
   },
   "source": [
    "## Lowest Overall Entropy or mse?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ge77P86wonjl"
   },
   "outputs": [],
   "source": [
    "## MSE LOSS\n",
    "\n",
    "def mse(data):\n",
    "    actual_values = data[:, -1]\n",
    "    if len(actual_values) == 0:   # empty data\n",
    "        mse = 0\n",
    "        \n",
    "    else:\n",
    "        prediction = np.mean(actual_values)\n",
    "        mse = np.mean((actual_values - prediction) **2)\n",
    "    \n",
    "    return mse\n",
    "\n",
    "\n",
    "# Entropy loss\n",
    "''' Calculating entropy loss '''\n",
    "\n",
    "def entropy(data):\n",
    "    \n",
    "    label_column = data[:, -1]\n",
    "    _, counts = np.unique(label_column, return_counts=True)\n",
    "\n",
    "    probabilities = counts / counts.sum()\n",
    "    entropy = sum(probabilities * -np.log2(probabilities))\n",
    "     \n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n3TG6bzHcgdk"
   },
   "outputs": [],
   "source": [
    "# GINI IMPURITY\n",
    "\n",
    "def gini(data):\n",
    "  label_column = data[:, -1]\n",
    "  _, counts = np.unique(label_column, return_counts=True)\n",
    "  probabilities = counts / counts.sum()\n",
    "  gini_index = 0\n",
    "\n",
    "  for i in probabilities:\n",
    "    gini_index += i ** 2\n",
    "  \n",
    "  return 1 - gini_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "z49fjIYZdwrw"
   },
   "outputs": [],
   "source": [
    "def calculate_overall_metric(data_below, data_above, metric_function):\n",
    "    \n",
    "    n = len(data_below) + len(data_above)\n",
    "    p_data_below = len(data_below) / n\n",
    "    p_data_above = len(data_above) / n\n",
    "    # weighted MSE, RMSE, Gini, and entropy\n",
    "    overall_metric =  (p_data_below * metric_function(data_below) \n",
    "                     + p_data_above * metric_function(data_above))\n",
    "    \n",
    "    return overall_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q-DD_4QQfQu_"
   },
   "outputs": [],
   "source": [
    "def determine_best_split(data, potential_splits, ml_task, criterion):\n",
    "    \n",
    "    first_iteration = True\n",
    "    for column_index in potential_splits:\n",
    "        for value in potential_splits[column_index]:\n",
    "            data_below, data_above = split_data(data, split_column=column_index, split_value=value)\n",
    "            \n",
    "            if ml_task == \"regression\":\n",
    "                current_overall_metric = calculate_overall_metric(data_below, data_above, metric_function=criterion)\n",
    "            \n",
    "            # classification\n",
    "            else:\n",
    "                current_overall_metric = calculate_overall_metric(data_below, data_above, metric_function=criterion)\n",
    "\n",
    "            if first_iteration or current_overall_metric <= best_overall_metric:\n",
    "                first_iteration = False\n",
    "                \n",
    "                best_overall_metric = current_overall_metric\n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "    \n",
    "    return best_split_column, best_split_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ohx0CCsRKHpR"
   },
   "source": [
    "## Determine the type of feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dbUkqouDKKT4"
   },
   "outputs": [],
   "source": [
    "def determine_type_of_feature(df):\n",
    "    feature_types = []\n",
    "    n_unique_values_treshold = 10\n",
    "    for feature in df.columns:\n",
    "        if feature != \"label\":\n",
    "            unique_values = df[feature].unique()\n",
    "            example_value = unique_values[0]\n",
    "\n",
    "            if (isinstance(example_value, str)) or (len(unique_values) <= n_unique_values_treshold):\n",
    "                feature_types.append(\"categorical\")\n",
    "            else:\n",
    "                feature_types.append(\"continuous\")\n",
    "    \n",
    "    return feature_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gy5JP8b_lbvn"
   },
   "source": [
    "## Decision Tree Algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xlw9mtuqlft-"
   },
   "outputs": [],
   "source": [
    "def decision_tree_algorithm(df, ml_task, counter=0, min_samples=2, min_samples_split = 2,max_depth=5, criterion = gini, max_leaf_nodes = 3):\n",
    "    \n",
    "    # data preparations\n",
    "    if counter == 0:\n",
    "        global COLUMN_HEADERS, FEATURE_TYPES, current_leaf_node\n",
    "        current_leaf_node = 0\n",
    "        COLUMN_HEADERS = df.columns\n",
    "        FEATURE_TYPES = determine_type_of_feature(df)\n",
    "        data = df.values\n",
    "\n",
    "    else:\n",
    "        data = df           \n",
    "    \n",
    "    # if ()\n",
    "    # base cases\n",
    "    if (check_purity(data)) or (len(data) < min_samples) or (counter == max_depth):\n",
    "        leaf = create_leaf(data, ml_task)\n",
    "        current_leaf_node += 1\n",
    "        return leaf\n",
    " \n",
    "    # recursive part\n",
    "    else:    \n",
    "        counter += 1\n",
    "        if (len(data) < min_samples_split):\n",
    "          leaf = create_leaf(data, ml_task)\n",
    "          current_leaf_node += 1\n",
    "        else:\n",
    "          # helper functions \n",
    "          potential_splits = get_potential_splits(data)\n",
    "          split_column, split_value = determine_best_split(data, potential_splits, ml_task,criterion = criterion)\n",
    "          data_below, data_above = split_data(data, split_column, split_value)\n",
    "          \n",
    "          # check for empty data\n",
    "          if len(data_below) == 0 or len(data_above) == 0:\n",
    "              leaf = create_leaf(data, ml_task)\n",
    "              current_leaf_node += 1\n",
    "              return leaf\n",
    "          \n",
    "          # determine question\n",
    "          feature_name = COLUMN_HEADERS[split_column]\n",
    "          type_of_feature = FEATURE_TYPES[split_column]\n",
    "          if type_of_feature == \"continuous\":\n",
    "              question = \"{} <= {}\".format(feature_name, split_value)\n",
    "              \n",
    "          # feature is categorical\n",
    "          else:\n",
    "              question = \"{} = {}\".format(feature_name, split_value)\n",
    "          \n",
    "          # instantiate sub-tree\n",
    "          sub_tree = {question: []}\n",
    "          \n",
    "          # find answers (recursion)\n",
    "          yes_answer = decision_tree_algorithm(data_below, ml_task, counter, min_samples, min_samples_split,max_depth, criterion)\n",
    "          no_answer = decision_tree_algorithm(data_above, ml_task, counter, min_samples,min_samples_split, max_depth, criterion)\n",
    "          \n",
    "          # If the answers are the same, then there is no point in asking the qestion.\n",
    "          # This could happen when the data is classified even though it is not pure\n",
    "          # yet (min_samples or max_depth base case).\n",
    "            \n",
    "          if yes_answer == no_answer:\n",
    "              sub_tree = yes_answer\n",
    "          else:\n",
    "              sub_tree[question].append(yes_answer)\n",
    "              sub_tree[question].append(no_answer)\n",
    "          \n",
    "          \n",
    "          return sub_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X0kcl_kooIsN"
   },
   "outputs": [],
   "source": [
    "X_train['label'] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vXl3vF8Oo_Il",
    "outputId": "a98d1e00-aaac-4052-eda5-7263fbf545d0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 66.8 ms, sys: 11.6 ms, total: 78.3 ms\n",
      "Wall time: 73.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tree_gini = decision_tree_algorithm(X_train, max_depth=5, ml_task=\"classification\", criterion = gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RRRRc4MjoM1F",
    "outputId": "8a1b52cf-c9de-4f50-9560-494ed78b00a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PetalWidthCm <= 0.4': ['Iris-setosa',\n",
      "                         {'PetalWidthCm <= 1.7': [{'PetalLengthCm <= 4.9': [{'PetalWidthCm <= 1.6': ['Iris-versicolor',\n",
      "                                                                                                     'Iris-virginica']},\n",
      "                                                                            {'PetalWidthCm <= 1.5': ['Iris-virginica',\n",
      "                                                                                                     {'PetalLengthCm <= 5.1': ['Iris-versicolor',\n",
      "                                                                                                                               'Iris-virginica']}]}]},\n",
      "                                                  'Iris-virginica']}]}\n"
     ]
    }
   ],
   "source": [
    "pprint(tree_gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "REmpSBzsI0VB",
    "outputId": "4db41c41-a3b6-4631-bf6c-ace7b6b2407c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PetalWidthCm <= 0.4 (Node: 1)': ['0.0 Node: 2',\n",
      "                                   {'PetalWidthCm <= 1.7 (Node: 3)': [{'PetalLengthCm <= 4.9 (Node: 4)': [{'PetalWidthCm <= 1.6 (Node: 6)': ['1.0 '\n",
      "                                                                                                                                             'Node: '\n",
      "                                                                                                                                             '8',\n",
      "                                                                                                                                             '2.0 '\n",
      "                                                                                                                                             'Node: '\n",
      "                                                                                                                                             '5']},\n",
      "                                                                                                          {'PetalWidthCm <= 1.5 (Node: 7)': ['2.0 '\n",
      "                                                                                                                                             'Node: '\n",
      "                                                                                                                                             '10',\n",
      "                                                                                                                                             {'PetalLengthCm <= 5.1 (Node: 9)': ['1.0 '\n",
      "                                                                                                                                                                                 'Node: '\n",
      "                                                                                                                                                                                 '12',\n",
      "                                                                                                                                                                                 '2.0 '\n",
      "                                                                                                                                                                                 'Node: '\n",
      "                                                                                                                                                                                 '11']}]}]},\n",
      "                                                                      '2.0 '\n",
      "                                                                      'Node: '\n",
      "                                                                      '13']}]}\n"
     ]
    }
   ],
   "source": [
    "pprint(complete_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WAv4Wa8i-r5J",
    "outputId": "ddb52af4-b80d-4a51-dd08-3620f4b53b48"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_leaf_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iPIYqJxtniiG",
    "outputId": "a8890a05-4d22-4e48-e2a8-653e63b715d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 120 ms, sys: 16.1 ms, total: 136 ms\n",
      "Wall time: 124 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tree_entropy = decision_tree_algorithm(X_train, max_depth=5, ml_task=\"classification\", criterion = entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CMP4ypPh-Jcr"
   },
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x9BmkieI-M9M"
   },
   "outputs": [],
   "source": [
    "def predict_example(example, tree):\n",
    "    question = list(tree.keys())[0]\n",
    "    feature_name, comparison_operator, value = question.split(\" \")\n",
    "\n",
    "    # ask question\n",
    "    if comparison_operator == \"<=\":\n",
    "        if example[feature_name] <= float(value):\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "    \n",
    "    # feature is categorical\n",
    "    else:\n",
    "        if str(example[feature_name]) == value:\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "\n",
    "    # base case\n",
    "    if not isinstance(answer, dict):\n",
    "        return answer\n",
    "    \n",
    "    # recursive part\n",
    "    else:\n",
    "        residual_tree = answer\n",
    "        return predict_example(example, residual_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1BbnhiiR18Hb"
   },
   "outputs": [],
   "source": [
    "tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nTHfKDq81Fjj",
    "outputId": "f9883e42-44eb-4fb9-cf56-3a0d7e7b864e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20         Iris-setosa\n",
       "134     Iris-virginica\n",
       "123     Iris-virginica\n",
       "138     Iris-virginica\n",
       "137     Iris-virginica\n",
       "            ...       \n",
       "83     Iris-versicolor\n",
       "65     Iris-versicolor\n",
       "95     Iris-versicolor\n",
       "8          Iris-setosa\n",
       "66     Iris-versicolor\n",
       "Length: 112, dtype: object"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.apply(predict_example, axis=1, args=(tree_gini,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rz07BJtUBvzb",
    "outputId": "7f9c3456-636a-4407-cd6d-4064b3fce463"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For training data\n",
      "tree_gini:  1.0\n",
      "tree_entropy:  1.0\n",
      "\n",
      "For testing data\n",
      "tree_gini:  0.9210526315789473\n",
      "tree_entropy:  0.9210526315789473\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy(df, tree):\n",
    "\n",
    "    df[\"classification\"] = df.apply(predict_example, axis=1, args=(tree,))\n",
    "    df[\"classification_correct\"] = df[\"classification\"] == df[\"label\"]\n",
    "    \n",
    "    accuracy = df[\"classification_correct\"].mean()\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "X_test['label'] = y_test\n",
    "\n",
    "print(\"For training data\")\n",
    "print(\"tree_gini: \", calculate_accuracy(X_train, tree_gini))\n",
    "print(\"tree_entropy: \", calculate_accuracy(X_train, tree_entropy))\n",
    "\n",
    "print(\"\\nFor testing data\")\n",
    "print(\"tree_gini: \", calculate_accuracy(X_test, tree_gini))\n",
    "print(\"tree_entropy: \", calculate_accuracy(X_test, tree_entropy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ty4j0heWagmg"
   },
   "source": [
    "# Post pruning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vy-iLLnxKYxA"
   },
   "outputs": [],
   "source": [
    "def predict_example(example, tree):\n",
    "    question = list(tree.keys())[0]\n",
    "    feature_name, comparison_operator, value = question.split(\" \")\n",
    "\n",
    "    # ask question\n",
    "    if comparison_operator == \"<=\":\n",
    "        if example[feature_name] <= float(value):\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "    \n",
    "    # feature is categorical\n",
    "    else:\n",
    "        if str(example[feature_name]) == value:\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "\n",
    "    # base case\n",
    "    if not isinstance(answer, dict):\n",
    "        return answer\n",
    "    \n",
    "    # recursive part\n",
    "    else:\n",
    "        residual_tree = answer\n",
    "        return predict_example(example, residual_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OVIdceSKrAHw"
   },
   "outputs": [],
   "source": [
    "# 3.2 All examples of a dataframe\n",
    "def make_predictions(df, tree):\n",
    "    \n",
    "    if len(df) != 0:\n",
    "        predictions = df.apply(predict_example, args=(tree,), axis=1)\n",
    "    else:\n",
    "        # \"df.apply()\"\" with empty dataframe returns an empty dataframe,\n",
    "        # but \"predictions\" should be a series instead\n",
    "        predictions = pd.Series()\n",
    "        \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3aIPLbxYk9QL"
   },
   "outputs": [],
   "source": [
    "def filter_df(df, question):\n",
    "    feature, comparison_operator, value = question.split()\n",
    "    \n",
    "    # continuous feature\n",
    "    if comparison_operator == \"<=\":\n",
    "        df_yes = df[df[feature] <= float(value)]\n",
    "        df_no =  df[df[feature] >  float(value)]\n",
    "        \n",
    "    # categorical feature\n",
    "    else:\n",
    "        df_yes = df[df[feature].astype(str) == value]\n",
    "        df_no  = df[df[feature].astype(str) != value]\n",
    "    \n",
    "    return df_yes, df_no"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h7ZfPfXznPDb"
   },
   "outputs": [],
   "source": [
    "def determine_leaf(df_train, ml_task):\n",
    "    \n",
    "    if ml_task == \"regression\":\n",
    "        return df_train.label.mean()\n",
    "    \n",
    "    # classification\n",
    "    else:\n",
    "        return df_train.label.value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wMP7b4byyAdg"
   },
   "outputs": [],
   "source": [
    "def determine_traning_mode_or_mean_errors(df_val, leaf, ml_task):\n",
    "    predictions = leaf\n",
    "    actual_values = df_val.label\n",
    "    \n",
    "    if ml_task == \"regression\":\n",
    "        # mean squared error\n",
    "        return ((predictions - actual_values) **2).mean()\n",
    "    else:\n",
    "        # number of errors\n",
    "        return sum(predictions != actual_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wGYL6hoenRK6"
   },
   "outputs": [],
   "source": [
    "def determine_descision_node_errors(df_val, tree, ml_task):\n",
    "    predictions = make_predictions(df_val, tree)\n",
    "    actual_values = df_val.label\n",
    "    \n",
    "    if ml_task == \"regression\":\n",
    "        # mean squared error\n",
    "        return ((predictions - actual_values) **2).mean()\n",
    "    else:\n",
    "        # number of errors\n",
    "        return sum(predictions != actual_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1Ewj6YH1kxKV"
   },
   "outputs": [],
   "source": [
    "def pruning_result(tree, df_train, df_val, ml_task):\n",
    "    \n",
    "    leaf = determine_leaf(df_train, ml_task)\n",
    "    errors_leaf = determine_traning_mode_or_mean_errors(df_val, leaf, ml_task) # training data ko mode/mean use garera validation ma nikalney error\n",
    "    errors_decision_node = determine_descision_node_errors(df_val, tree, ml_task) # actual validation error\n",
    "\n",
    "    if errors_leaf <= errors_decision_node:\n",
    "        return leaf\n",
    "    else:\n",
    "        return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "r1ZoP2nwSJH1"
   },
   "outputs": [],
   "source": [
    "def post_pruning(tree, df_train, df_val, ml_task):\n",
    "    \n",
    "    question = list(tree.keys())[0]\n",
    "    yes_answer, no_answer = tree[question]\n",
    "\n",
    "    # base case\n",
    "    if not isinstance(yes_answer, dict) and not isinstance(no_answer, dict):\n",
    "        return pruning_result(tree, df_train, df_val, ml_task)\n",
    "        \n",
    "    # recursive part\n",
    "    else:\n",
    "        df_train_yes, df_train_no = filter_df(df_train, question)\n",
    "        df_val_yes, df_val_no = filter_df(df_val, question)\n",
    "        \n",
    "        if isinstance(yes_answer, dict):\n",
    "            yes_answer = post_pruning(yes_answer, df_train_yes, df_val_yes, ml_task)\n",
    "            \n",
    "        if isinstance(no_answer, dict):\n",
    "            no_answer = post_pruning(no_answer, df_train_no, df_val_no, ml_task)\n",
    "        \n",
    "        tree = {question: [yes_answer, no_answer]}\n",
    "    \n",
    "        return pruning_result(tree, df_train, df_val, ml_task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KY343RQNI7Ax",
    "outputId": "cf9f4fb7-04b1-4968-bd3a-3fff9559bf1e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PetalWidthCm <= 0.4 (Node: 1)': ['0.0 Node: 2',\n",
      "                                   {'PetalWidthCm <= 1.7 (Node: 3)': [{'PetalLengthCm <= 4.9 (Node: 4)': [{'PetalWidthCm <= 1.6 (Node: 6)': ['1.0 '\n",
      "                                                                                                                                             'Node: '\n",
      "                                                                                                                                             '8',\n",
      "                                                                                                                                             '2.0 '\n",
      "                                                                                                                                             'Node: '\n",
      "                                                                                                                                             '5']},\n",
      "                                                                                                          {'PetalWidthCm <= 1.5 (Node: 7)': ['2.0 '\n",
      "                                                                                                                                             'Node: '\n",
      "                                                                                                                                             '10',\n",
      "                                                                                                                                             {'PetalLengthCm <= 5.1 (Node: 9)': ['1.0 '\n",
      "                                                                                                                                                                                 'Node: '\n",
      "                                                                                                                                                                                 '12',\n",
      "                                                                                                                                                                                 '2.0 '\n",
      "                                                                                                                                                                                 'Node: '\n",
      "                                                                                                                                                                                 '11']}]}]},\n",
      "                                                                      '2.0 '\n",
      "                                                                      'Node: '\n",
      "                                                                      '13']}]}\n"
     ]
    }
   ],
   "source": [
    "pprint(complete_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ThsGcD_OL1Gf"
   },
   "outputs": [],
   "source": [
    "X_test['label'] = y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "n2Nl0igmngsK",
    "outputId": "36d2d805-949f-4f2a-d3e3-9e5c0bf7990f"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-190-32b8f6cb5a35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpruned_tree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpost_pruning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomplete_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mml_task\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'classification'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-187-8e41d5d292e7>\u001b[0m in \u001b[0;36mpost_pruning\u001b[0;34m(tree, df_train, df_val, ml_task)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_answer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m             \u001b[0mno_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpost_pruning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_answer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_val_no\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mml_task\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mquestion\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0myes_answer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mno_answer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-187-8e41d5d292e7>\u001b[0m in \u001b[0;36mpost_pruning\u001b[0;34m(tree, df_train, df_val, ml_task)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myes_answer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0myes_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpost_pruning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myes_answer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train_yes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_val_yes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mml_task\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_answer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-187-8e41d5d292e7>\u001b[0m in \u001b[0;36mpost_pruning\u001b[0;34m(tree, df_train, df_val, ml_task)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myes_answer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0myes_answer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpost_pruning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myes_answer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train_yes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_val_yes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mml_task\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_answer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-187-8e41d5d292e7>\u001b[0m in \u001b[0;36mpost_pruning\u001b[0;34m(tree, df_train, df_val, ml_task)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;31m# base case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myes_answer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mno_answer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpruning_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mml_task\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;31m# recursive part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-186-087ea06f6dfe>\u001b[0m in \u001b[0;36mpruning_result\u001b[0;34m(tree, df_train, df_val, ml_task)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mleaf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetermine_leaf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mml_task\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0merrors_leaf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetermine_traning_mode_or_mean_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mml_task\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# training data ko mode/mean use garera validation ma nikalney error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0merrors_decision_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetermine_descision_node_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mml_task\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# actual validation error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0merrors_leaf\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0merrors_decision_node\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-185-289aabaae649>\u001b[0m in \u001b[0;36mdetermine_descision_node_errors\u001b[0;34m(df_val, tree, ml_task)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdetermine_descision_node_errors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mml_task\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mactual_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_val\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mml_task\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"regression\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-173-c9b0b09a353d>\u001b[0m in \u001b[0;36mmake_predictions\u001b[0;34m(df, tree)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_example\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;31m# \"df.apply()\"\" with empty dataframe returns an empty dataframe,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'predict_example'"
     ]
    }
   ],
   "source": [
    "pruned_tree = post_pruning(complete_tree, X_train, X_test, ml_task = 'classification')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ULc2oPYvUbP",
    "outputId": "a11923b7-0176-4f58-f607-0f19a78ffc77"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PetalWidthCm <= 0.6': ['Iris-setosa',\n",
       "  {'PetalLengthCm <= 4.7': ['Iris-versicolor',\n",
       "    {'PetalLengthCm <= 5.1': [{'PetalWidthCm <= 1.7': ['Iris-versicolor',\n",
       "        'Iris-virginica']},\n",
       "      'Iris-virginica']}]}]}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pruned_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I3_yv9S1ydXW",
    "outputId": "3f7284d9-5467-41e9-e093-e2765b28eb97"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9473684210526315"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_accuracy(X_test, tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qS0sGyKNzQdo",
    "outputId": "34feb882-f188-4dc4-b643-52048ffe3692"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calculate_accuracy(X_test, pruned_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "139iWNHh0HjN",
    "outputId": "8708774c-90ae-4349-b2d7-ed56f297b661"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PetalWidthCm <= 0.6': ['Iris-setosa',\n",
      "                         {'PetalLengthCm <= 4.7': [{'PetalWidthCm <= 1.6': ['Iris-versicolor',\n",
      "                                                                            'Iris-virginica']},\n",
      "                                                   {'PetalLengthCm <= 5.1': [{'PetalWidthCm <= 1.7': [{'SepalWidthCm <= 2.2': ['Iris-virginica',\n",
      "                                                                                                                               {'PetalLengthCm <= 5.0': ['Iris-versicolor',\n",
      "                                                                                                                                                         {'PetalWidthCm <= 1.5': ['Iris-virginica',\n",
      "                                                                                                                                                                                  'Iris-versicolor']}]}]},\n",
      "                                                                                                      {'SepalWidthCm <= 3.0': ['Iris-virginica',\n",
      "                                                                                                                               'Iris-versicolor']}]},\n",
      "                                                                             'Iris-virginica']}]}]}\n"
     ]
    }
   ],
   "source": [
    "pprint(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wdz-NI98zRue",
    "outputId": "ead20541-79bb-4542-ae08-54405548d7a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PetalWidthCm <= 0.6': ['Iris-setosa',\n",
      "                         {'PetalLengthCm <= 4.7': ['Iris-versicolor',\n",
      "                                                   {'PetalLengthCm <= 5.1': [{'PetalWidthCm <= 1.7': ['Iris-versicolor',\n",
      "                                                                                                      'Iris-virginica']},\n",
      "                                                                             'Iris-virginica']}]}]}\n"
     ]
    }
   ],
   "source": [
    "pprint(pruned_tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "07gYGe9F2aUO"
   },
   "source": [
    "# Final Codew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DescisionTree:\n",
    "  def __init__(self, criterion,ml_task = 'classification', min_samples_leaf=1, min_samples_split = 2, max_depth = 5):\n",
    "    self.data = None\n",
    "    self.X = None\n",
    "    self.y = None\n",
    "    self.ml_task = ml_task\n",
    "    self.min_samples_leaf = min_samples_leaf\n",
    "    self.min_samples_split = min_samples_split\n",
    "    self.max_depth = max_depth\n",
    "    self.metric = criterion\n",
    "    self.feature_importances_ = None\n",
    "    self.complete_tree = None\n",
    "    self.n_entries = {}\n",
    "    self.n_weighted_entries = {}\n",
    "    self.parent_node = 1  # root node\n",
    "    self.yes_node = 2     # left node\n",
    "    self.no_node = 3      # right node\n",
    "    self.leaf_count = 0\n",
    "    if ml_task == 'classification': self.classes_and_counts = {};self.leaf_node_class_proba = {}\n",
    "    else: self.leaf_node_loss = {}\n",
    "    \n",
    "\n",
    "  ''' This method is used to get the collective counts of all classes in target '''\n",
    "  def get_classes_and_counts(self, data):\n",
    "    label_column = data[:, -1]\n",
    "    unique_classes, counts_unique_classes = np.unique(label_column, return_counts=True)\n",
    "    for i in range(len(unique_classes)):\n",
    "      self.classes_and_counts[unique_classes[i]] = counts_unique_classes[i]\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "  ''' This method is used to get the collective probabilities of all classes in target '''\n",
    "  def get_probability_for_all_classes(self, data):\n",
    "    label_column = data[:, -1]\n",
    "    unique_classes_new, counts_unique_classes_new = np.unique(label_column, return_counts=True)\n",
    "    \n",
    "    classes_and_counts_new = {}\n",
    "    for i in list(self.classes_and_counts.keys()):\n",
    "      if i in list(unique_classes_new):\n",
    "        classes_and_counts_new[i] = counts_unique_classes_new[list(unique_classes_new).index(i)]\n",
    "      else:\n",
    "        classes_and_counts_new[i] = 0\n",
    "    array = np.array(list(classes_and_counts_new.values())) / sum(classes_and_counts_new.values())\n",
    "\n",
    "    return [round(i, 5) for i in array]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  ''' This method checks the purity of a target vector '''\n",
    "  def check_purity(self, data):\n",
    "      label_column = data[:, -1]\n",
    "      unique_classes = np.unique(label_column)\n",
    "      if len(unique_classes) == 1:\n",
    "          return True\n",
    "      else:\n",
    "          return False\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "  ''' This method performs classification '''\n",
    "  def create_leaf(self, data, ml_task, current_node):\n",
    "      self.leaf_count += 1\n",
    "      label_column = data[:, -1]\n",
    "      if ml_task == \"regression\":\n",
    "          leaf = np.mean(label_column)\n",
    "          self.leaf_node_loss[current_node] = self.mse(data)\n",
    "          return str(leaf) + ' Node: '+str(current_node)\n",
    "      else:\n",
    "          probabilities = []\n",
    "          unique_classes, counts_unique_classes = np.unique(label_column, return_counts=True)\n",
    "          index = counts_unique_classes.argmax()\n",
    "          leaf = unique_classes[index]\n",
    "          # probability = counts_unique_classes[index] / sum(counts_unique_classes)\n",
    "          self.leaf_node_class_proba[current_node] = self.get_probability_for_all_classes(data)\n",
    "          \n",
    "          return str(leaf) + ' Node: '+str(current_node)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "  ''' this function generates all possible potential splits for a given training data '''\n",
    "  def get_potential_splits(self, data):\n",
    "      potential_splits = {}\n",
    "      _, n_columns = data.shape\n",
    "      for column_index in range(n_columns - 1):   \n",
    "          values = data[:, column_index]\n",
    "          unique_values = np.unique(values)\n",
    "          potential_splits[column_index] = unique_values\n",
    "      \n",
    "      return potential_splits\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "  ''' This function splits the data into two partitions: Yes and no cases'''\n",
    "  def split_data(self, data, split_column, split_value):\n",
    "      split_column_values = data[:, split_column]\n",
    "      type_of_feature = FEATURE_TYPES[split_column]\n",
    "\n",
    "      if type_of_feature == \"continuous\":\n",
    "          data_below = data[split_column_values <= split_value]\n",
    "          data_above = data[split_column_values >  split_value]\n",
    "      else:\n",
    "          data_below = data[split_column_values == split_value]\n",
    "          data_above = data[split_column_values != split_value]\n",
    "      \n",
    "      return data_below, data_above\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "  ''' This method calculates mse loss'''\n",
    "  def mse(self, data):\n",
    "      actual_values = data[:, -1]\n",
    "      if len(actual_values) == 0:   # empty data\n",
    "          mse = 0\n",
    "      else:\n",
    "          prediction = np.mean(actual_values)\n",
    "          mse = np.mean((actual_values - prediction) **2)\n",
    "      \n",
    "      return mse\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "  ''' This method calculates entropy loss '''\n",
    "  def entropy(self, data):\n",
    "      label_column = data[:, -1]\n",
    "      _, counts = np.unique(label_column, return_counts=True)\n",
    "      probabilities = counts / counts.sum()\n",
    "      entropy = sum(probabilities * -np.log2(probabilities))\n",
    "      \n",
    "      return entropy\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "  ''' This method calculates gini impurity'''\n",
    "  def gini(self, data):\n",
    "    label_column = data[:, -1]\n",
    "    _, counts = np.unique(label_column, return_counts=True)\n",
    "    probabilities = counts / counts.sum()\n",
    "    gini_index = 0\n",
    "\n",
    "    for i in probabilities:\n",
    "      gini_index += i ** 2\n",
    "    \n",
    "    return 1 - gini_index\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  ''' calculating total/weighed value of the used metric '''\n",
    "  def calculate_overall_metric(self, data_below, data_above, metric_function):\n",
    "    n = len(data_below) + len(data_above)\n",
    "    p_data_below = len(data_below) / n\n",
    "    p_data_above = len(data_above) / n\n",
    "    # weighted MSE, RMSE, Gini, and entropy\n",
    "    overall_metric =  (p_data_below * metric_function(self, data_below) \n",
    "                     + p_data_above * metric_function(self, data_above))\n",
    "    \n",
    "    return overall_metric\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "  ''' Determining which split is the best by using the metric '''\n",
    "  def determine_best_split(self, data, potential_splits, ml_task, criterion):\n",
    "    first_iteration = True\n",
    "    for column_index in potential_splits:\n",
    "        for value in potential_splits[column_index]:\n",
    "            data_below, data_above = self.split_data(data, split_column=column_index, split_value=value)\n",
    "            \n",
    "        \n",
    "            current_overall_metric = self.calculate_overall_metric(data_below, data_above, metric_function=criterion)\n",
    "            if first_iteration or current_overall_metric <= best_overall_metric:\n",
    "                first_iteration = False\n",
    "                best_overall_metric = current_overall_metric\n",
    "                best_split_column = column_index\n",
    "                best_split_value = value\n",
    "    \n",
    "    return best_split_column, best_split_value\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  ''' determining the type of a feature among all features '''\n",
    "  def determine_type_of_feature(self, df):\n",
    "    feature_types = []\n",
    "    n_unique_values_treshold = 10\n",
    "\n",
    "    for feature in df.columns:\n",
    "        if feature != \"label\":\n",
    "            unique_values = df[feature].unique()\n",
    "            example_value = unique_values[0]\n",
    "            if (isinstance(example_value, str)) or (len(unique_values) <= n_unique_values_treshold):\n",
    "                feature_types.append(\"categorical\")\n",
    "            else:\n",
    "                feature_types.append(\"continuous\")\n",
    "    \n",
    "    return feature_types\n",
    "\n",
    "  \n",
    "    \n",
    "    \n",
    "    \n",
    "  ''' THIS IS THE MAIN RECURSIVE ALGORITHM FOR DESCISION TREE'''\n",
    "  def tree(self, df, ml_task, counter,current_node, min_samples_leaf, min_samples_split,max_depth, criterion, answer):\n",
    "\n",
    "    # When the tree starts, the dataframe is converteed to numpy array, the depth of the tree is checked using counter variable and all features types are detected\n",
    "    if counter == 0:\n",
    "        global COLUMN_HEADERS, FEATURE_TYPES\n",
    "        COLUMN_HEADERS = df.columns\n",
    "        FEATURE_TYPES = self.determine_type_of_feature(df)\n",
    "        data = df.values\n",
    "        criterion = getattr(DescisionTree, criterion)\n",
    "    else:\n",
    "        data = df      \n",
    "\n",
    "    # storing the length of data passed into the node\n",
    "    self.n_entries['Node: '+str(current_node)] = [len(df)]\n",
    "    # criterion = getattr(DescisionTree, criterion)\n",
    "\n",
    "    # storing the loss/mse/rmse/gini/entropy in a specific node\n",
    "    self.n_entries['Node: '+str(current_node)].append(criterion(self, data))\n",
    "    \n",
    "    # incrementing yes/left nodes and no/right nodes such that yes will be a even node and no will be a odd node repectively\n",
    "    if (answer == 'yes answer'):\n",
    "      self.yes_node += 2\n",
    "    elif (answer == 'no answer'):\n",
    "      self.no_node += 2 \n",
    "      \n",
    "    # checking if that target of the data passed is either pure, has minimum samples to create a leaf, or the depth of tree has reached its maximum depth\n",
    "    if (self.check_purity(data)) or (len(data) == min_samples_leaf) or (counter == max_depth):\n",
    "        leaf = self.create_leaf(data, ml_task, current_node) # creating the leaf\n",
    "        return leaf \n",
    "    # if above requirements to create a leaf are not met, two new nodes will be created recursively respectively.\n",
    "    else:    \n",
    "        counter += 1 # when two new nodes are created, the depth of three is also incremented\n",
    "        \n",
    "        # if the data is not yet pure, but has not minimum samples to perform the split, a leaf is created\n",
    "        if (len(data) < min_samples_split):\n",
    "          leaf = self.create_leaf(data, ml_task, current_node)\n",
    "          return leaf\n",
    "        else:\n",
    "          # getting the all possible splits, determining which split has least loss, and splitting the data into left and right nodes respectively\n",
    "          potential_splits = self.get_potential_splits(data)\n",
    "          split_column, split_value = self.determine_best_split(data, potential_splits, ml_task,criterion)\n",
    "          data_below, data_above = self.split_data(data, split_column, split_value)\n",
    "          \n",
    "          # if the data seperated into left and right nodes, but there is no data, instead of creating a node, a leaft is created\n",
    "          if len(data_below) == 0 or len(data_above) == 0:\n",
    "              leaf = self.create_leaf(data, ml_task, current_node)\n",
    "              return leaf\n",
    "          \n",
    "          # finding the type of a selected feature column and its name\n",
    "          feature_name = COLUMN_HEADERS[split_column]\n",
    "          type_of_feature = FEATURE_TYPES[split_column]\n",
    "\n",
    "#           # creating the tree questions\n",
    "          if type_of_feature == \"continuous\":\n",
    "              question = \"{} <= {} (Node: {})\".format(feature_name, split_value, current_node)\n",
    "          # feature is categorical\n",
    "          else:\n",
    "              question = \"{} = {} (Node: {})\".format(feature_name, split_value, current_node)\n",
    "\n",
    "          # instantiate sub-tree\n",
    "          sub_tree = {question: []}\n",
    "\n",
    "          # creating left and right nodes recursively\n",
    "          yes_answer = self.tree(data_below, ml_task, counter, self.yes_node,min_samples_leaf, min_samples_split,max_depth, criterion, 'yes answer')\n",
    "          no_answer = self.tree(data_above, ml_task, counter, self.no_node,min_samples_leaf,min_samples_split, max_depth, criterion, 'no answer')\n",
    "          \n",
    "          # if both left and right nodes are same, only taking one value for a leaf node\n",
    "          if yes_answer == no_answer:\n",
    "              sub_tree = yes_answer\n",
    "          else:\n",
    "            sub_tree[question].append(yes_answer)\n",
    "            sub_tree[question].append(no_answer)\n",
    "          \n",
    "          return sub_tree\n",
    "\n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "  ''' making predictions using this tree '''\n",
    "  def predict_example(self, example, tree):\n",
    "    question = list(tree.keys())[0]\n",
    "    feature_name, comparison_operator, value = question.split(\" \")[:3]\n",
    "\n",
    "    # ask question\n",
    "    if comparison_operator == \"<=\":\n",
    "        if example[feature_name] <= float(value):\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "    # feature is categorical\n",
    "    else:\n",
    "        if str(example[feature_name]) == value:\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "    # base case\n",
    "    if not isinstance(answer, dict):\n",
    "        return float(answer.split()[0])\n",
    "    \n",
    "    # recursive part\n",
    "    else:\n",
    "        residual_tree = answer\n",
    "        return self.predict_example(example, residual_tree)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "  ''' making probability of the predictions using this tree '''\n",
    "  def predict_example_probability(self, example, tree):\n",
    "    question = list(tree.keys())[0]\n",
    "    feature_name, comparison_operator, value = question.split(\" \")[:3]\n",
    "\n",
    "    # ask question\n",
    "    if comparison_operator == \"<=\":\n",
    "        if example[feature_name] <= float(value):\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "    # feature is categorical\n",
    "    else:\n",
    "        if str(example[feature_name]) == value:\n",
    "            answer = tree[question][0]\n",
    "        else:\n",
    "            answer = tree[question][1]\n",
    "    # base case\n",
    "    if not isinstance(answer, dict):\n",
    "        return int(answer.split()[2])\n",
    "            \n",
    "    # recursive part\n",
    "    else:\n",
    "        residual_tree = answer\n",
    "        return self.predict_example_probability(example, residual_tree)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "  ''' fitting our tree with training data '''\n",
    "  def fit(self, X,y):\n",
    "    self.X = X.copy();self.y = y.copy()\n",
    "    self.X['label'] = self.y;self.data = self.X\n",
    "\n",
    "    if self.ml_task == 'classification':\n",
    "      self.get_classes_and_counts(self.data.values)\n",
    "    self.complete_tree = self.tree(self.data, self.ml_task, 0,self.parent_node, self.min_samples_leaf, self.min_samples_split, self.max_depth, self.metric,'parent_node')\n",
    "\n",
    "    # calculating weighted entries\n",
    "    for key, value in self.n_entries.items():\n",
    "      self.n_weighted_entries[key] = [value[0] / len(self.X), value[1]]\n",
    "\n",
    "    return self.complete_tree\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  ''' Making predictions '''\n",
    "  def predict(self, X):\n",
    "    # X_train.apply(predict_example, axis=1, args=(tree_gini,))\n",
    "    predictions = np.array(X.apply(self.predict_example, axis = 1, args = (self.complete_tree, )))\n",
    "    \n",
    "    return predictions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  ''' This method returns the predicted probabilities for all classes '''\n",
    "  def predict_proba(self, X):\n",
    "    leaf_nodes_for_predictions = np.array(X.apply(self.predict_example_probability, axis = 1, args = (self.complete_tree, )))\n",
    "    probabilities = [] \n",
    "    \n",
    "    \n",
    "    for i in leaf_nodes_for_predictions:\n",
    "      for key, value in self.leaf_node_class_proba.items():\n",
    "        if i == key:\n",
    "          probabilities.append(list(value))\n",
    "\n",
    "    return probabilities"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Descision Trees.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
