{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gmYUQQ0Xi-WY"
   },
   "source": [
    "# Credit Card fraud prediction using original and custom model without smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WmAUbkS5jiL_"
   },
   "outputs": [],
   "source": [
    "!pip install opendatasets --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uV-SDTqGjjl9"
   },
   "outputs": [],
   "source": [
    "import opendatasets as od\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "keQsR-xDojYx"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from numpy import log,dot,exp,shape\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mqoOjuyAjred",
    "outputId": "3fbd21f6-9301-47b5-8872-a8eb7c7e1513"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please provide your Kaggle credentials to download this dataset. Learn more: http://bit.ly/kaggle-creds\n",
      "Your Kaggle username: royalalbert\n",
      "Your Kaggle Key: ··········\n",
      "Downloading creditcardfraud.zip to ./creditcardfraud\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 66.0M/66.0M [00:00<00:00, 179MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "link = 'https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud'\n",
    "od.download(link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "21appWiLkDLd",
    "outputId": "e66e39ef-3593-4b30-e46c-fcdf01fc7afe"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-af5c2ad7-a0e9-4c9e-a0fd-c04bb7cdb2ba\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-af5c2ad7-a0e9-4c9e-a0fd-c04bb7cdb2ba')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-af5c2ad7-a0e9-4c9e-a0fd-c04bb7cdb2ba button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-af5c2ad7-a0e9-4c9e-a0fd-c04bb7cdb2ba');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(r'/content/creditcardfraud/creditcard.csv');df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q9COWZXEkHdN"
   },
   "outputs": [],
   "source": [
    "df['NormAmt'] = StandardScaler().fit_transform(df[['Amount']])\n",
    "X = df[df.columns.to_list()[1:]].drop(['Class', 'Amount'], axis = 1)\n",
    "y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nqKQva0mjzox"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split    # create a custom k-fold cross validation.. dont use train test split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25, random_state = 42)\n",
    "# X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.15, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d81afs79keSt",
    "outputId": "f3a87c5f-fd71-4f55-ec66-ca07ee1f1b2f"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:29<00:00,  3.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Training accuracy:  0.9988951569485733\n",
      "Final Testing accuracy:,  0.9990028369989608\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71089\n",
      "           1       0.81      0.49      0.61       113\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.90      0.74      0.80     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class LogisticRegressionCustom:\n",
    "    def __init__(self, lr, epochs):      \n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.weight = 0\n",
    "        self.bias = 0\n",
    "        self.loss = []\n",
    "        self.accuracy_record = []\n",
    "        self.weight_record = []\n",
    "        self.bias_record = []\n",
    "        self.epoch_record = []\n",
    "\n",
    "    def get_clean_output(self, preds):\n",
    "      threshold_prob = 0.5\n",
    "      result = preds >= threshold_prob\n",
    "      y_pred = np.zeros(result.shape[0])\n",
    "      for i in range(len(y_pred)):\n",
    "          if result[i] == True: \n",
    "              y_pred[i] = 1\n",
    "          else:\n",
    "              continue\n",
    "                 \n",
    "      return y_pred\n",
    "\n",
    "\n",
    "    def _accuracy(self, target, predictions):\n",
    "      accuracy = 0\n",
    "      for i in range(len(predictions)):\n",
    "        if (predictions[i] == target[i]):\n",
    "          accuracy += 1\n",
    "\n",
    "      return accuracy / len(target)\n",
    "\n",
    "    # Sigmoid method\n",
    "    def sigmoid(self, x, weight, bias):\n",
    "        z = np.dot(x, weight) + bias\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "     \n",
    "    # method to calculate the binary cross entropy Loss\n",
    "    def BCE_loss(self, preds, y):\n",
    "        return (-y * np.log(preds) - (1 - y) * np.log(1 - preds)).mean()\n",
    "\n",
    "    # method for calculating the gradients\n",
    "    def gradient_descent(self, X, preds, target):\n",
    "      d_loss_wrt_weight = (1 / X.shape[0]) * np.dot(X.T, (preds - target)) \n",
    "      d_loss_wrt_bias =  (1 / X.shape[0]) * np.sum(preds - target)\n",
    "      return d_loss_wrt_weight, d_loss_wrt_bias\n",
    "     \n",
    "    def fit(self, X, y, X_val, y_val):\n",
    "      self.weight = np.zeros(X.shape[1])\n",
    "      # training set\n",
    "      X = X.values\n",
    "      y = y.values\n",
    "\n",
    "      # Validation set\n",
    "      X_val = X_val.values\n",
    "      y_val = y_val.values\n",
    "\n",
    "      # training\n",
    "      for i in tqdm(range(self.epochs)):\n",
    "        predictions = self.sigmoid(X, self.weight, self.bias)\n",
    "        loss = self.BCE_loss(predictions, y)\n",
    "        dW, dB = self.gradient_descent(X, predictions, y)\n",
    "        \n",
    "        # recording items\n",
    "        self.loss.append(loss)\n",
    "        # recording validation accuracy\n",
    "        self.accuracy_record.append(self._accuracy(y_val, self.get_clean_output(self.sigmoid(X_val, self.weight, self.bias))))\n",
    "        self.weight_record.append(self.weight)\n",
    "        self.bias_record.append(self.bias)\n",
    "        self.epoch_record.append(i)\n",
    " \n",
    "        # Updating the weights\n",
    "        self.weight -= self.lr * dW\n",
    "        self.bias -= self.lr * dB\n",
    "     \n",
    "    # Method to predict the class label.\n",
    "    def predict(self, x_new):\n",
    "        test_preds = self.sigmoid(x_new, self.weight, self.bias)\n",
    "        return self.get_clean_output(test_preds)\n",
    "\n",
    "\n",
    "log_reg = LogisticRegressionCustom(0.1, 100)\n",
    "log_reg.fit(X_train, y_train,X_test,y_test)\n",
    "preds = log_reg.predict(X_test)\n",
    "print(\"\\nFinal Training accuracy: \",log_reg._accuracy(y_train.values, log_reg.predict(X_train)))\n",
    "print(\"Final Testing accuracy:, \", log_reg._accuracy(y_test.values, preds))\n",
    "\n",
    "# print classification report\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5MdUCrL3OF-f",
    "outputId": "b0c0d010-9e1c-4ceb-bde9-ccfdfa8d8bca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     71089\n",
      "           1       0.85      0.60      0.70       113\n",
      "\n",
      "    accuracy                           1.00     71202\n",
      "   macro avg       0.92      0.80      0.85     71202\n",
      "weighted avg       1.00      1.00      1.00     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logistic regression object\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "  \n",
    "# train the model on train set\n",
    "lr.fit(X_train, y_train)\n",
    "  \n",
    "predictions = lr.predict(X_test)\n",
    "  \n",
    "# print classification report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zlHR4onbo-r0"
   },
   "source": [
    "# Credit Card fraud prediction using original and custom model with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wd6m6cXzpcfb"
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "oversample = SMOTE(random_state = 42)\n",
    "X_smote, y_smote = oversample.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kMvetExgpq5M",
    "outputId": "1da6a2e9-8fb8-4a09-9cf6-aabd1cc0d8dc"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:29<00:00,  3.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Training accuracy:  0.9417050453509422\n",
      "Final Testing accuracy:,  0.9736243363950451\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     71089\n",
      "           1       0.05      0.91      0.10       113\n",
      "\n",
      "    accuracy                           0.97     71202\n",
      "   macro avg       0.53      0.94      0.54     71202\n",
      "weighted avg       1.00      0.97      0.99     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "class LogisticRegressionCustom:\n",
    "    def __init__(self, lr, epochs):      \n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.weight = 0\n",
    "        self.bias = 0\n",
    "        self.loss = []\n",
    "        self.accuracy_record = []\n",
    "        self.weight_record = []\n",
    "        self.bias_record = []\n",
    "        self.epoch_record = []\n",
    "\n",
    "    def get_clean_output(self, preds):\n",
    "      threshold_prob = 0.5\n",
    "      result = preds >= threshold_prob\n",
    "      y_pred = np.zeros(result.shape[0])\n",
    "      for i in range(len(y_pred)):\n",
    "          if result[i] == True: \n",
    "              y_pred[i] = 1\n",
    "          else:\n",
    "              continue\n",
    "                 \n",
    "      return y_pred\n",
    "\n",
    "\n",
    "    def _accuracy(self, target, predictions):\n",
    "      accuracy = 0\n",
    "      for i in range(len(predictions)):\n",
    "        if (predictions[i] == target[i]):\n",
    "          accuracy += 1\n",
    "\n",
    "      return accuracy / len(target)\n",
    "\n",
    "    # Sigmoid method\n",
    "    def sigmoid(self, x, weight, bias):\n",
    "        z = np.dot(x, weight) + bias\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "     \n",
    "    # method to calculate the binary cross entropy Loss\n",
    "    def BCE_loss(self, preds, y):\n",
    "        return (-y * np.log(preds) - (1 - y) * np.log(1 - preds)).mean()\n",
    "\n",
    "    # method for calculating the gradients\n",
    "    def gradient_descent(self, X, preds, target):\n",
    "      d_loss_wrt_weight = (1 / X.shape[0]) * np.dot(X.T, (preds - target)) \n",
    "      d_loss_wrt_bias =  (1 / X.shape[0]) * np.sum(preds - target)\n",
    "      return d_loss_wrt_weight, d_loss_wrt_bias\n",
    "     \n",
    "    def fit(self, X, y, X_val, y_val):\n",
    "      self.weight = np.zeros(X.shape[1])\n",
    "      # training set\n",
    "      X = X.values\n",
    "      y = y.values\n",
    "\n",
    "      # Validation set\n",
    "      X_val = X_val.values\n",
    "      y_val = y_val.values\n",
    "\n",
    "      # training\n",
    "      for i in tqdm(range(self.epochs)):\n",
    "        predictions = self.sigmoid(X, self.weight, self.bias)\n",
    "        loss = self.BCE_loss(predictions, y)\n",
    "        dW, dB = self.gradient_descent(X, predictions, y)\n",
    "        \n",
    "        # recording items\n",
    "        self.loss.append(loss)\n",
    "        # recording validation accuracy\n",
    "        self.accuracy_record.append(self._accuracy(y_val, self.get_clean_output(self.sigmoid(X_val, self.weight, self.bias))))\n",
    "        self.weight_record.append(self.weight)\n",
    "        self.bias_record.append(self.bias)\n",
    "        self.epoch_record.append(i)\n",
    " \n",
    "        # Updating the weights\n",
    "        self.weight -= self.lr * dW\n",
    "        self.bias -= self.lr * dB\n",
    "     \n",
    "    # Method to predict the class label.\n",
    "    def predict(self, x_new):\n",
    "        test_preds = self.sigmoid(x_new, self.weight, self.bias)\n",
    "        return self.get_clean_output(test_preds)\n",
    "\n",
    "\n",
    "log_reg = LogisticRegressionCustom(0.1, 100)\n",
    "log_reg.fit(X_smote, y_smote,X_test,y_test)\n",
    "preds = log_reg.predict(X_test)\n",
    "print(\"\\nFinal Training accuracy: \",log_reg._accuracy(y_smote.values, log_reg.predict(X_smote)))\n",
    "print(\"Final Testing accuracy:, \", log_reg._accuracy(y_test.values, preds))\n",
    "\n",
    "# print classification report\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "viaLQV5fqEyr",
    "outputId": "3582c338-78fc-4c37-b9af-0a679e8d4a4b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     71089\n",
      "           1       0.05      0.92      0.10       113\n",
      "\n",
      "    accuracy                           0.97     71202\n",
      "   macro avg       0.53      0.95      0.54     71202\n",
      "weighted avg       1.00      0.97      0.99     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# logistic regression object\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "  \n",
    "# train the model on train set\n",
    "lr.fit(X_smote, y_smote)\n",
    "  \n",
    "predictions = lr.predict(X_test)\n",
    "  \n",
    "# print classification report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YWpghMpGIFGt"
   },
   "source": [
    "# Gradient Descent with Momentum with smote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8yT0Zsj_JaC8",
    "outputId": "29dcfad1-e2d4-417b-ca76-86bad1f0149d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:07<00:00, 12.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final Training accuracy:  0.9417050453509422\n",
      "Final Testing accuracy:,  0.9736243363950451\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     71089\n",
      "           1       0.05      0.91      0.10       113\n",
      "\n",
      "    accuracy                           0.97     71202\n",
      "   macro avg       0.53      0.94      0.54     71202\n",
      "weighted avg       1.00      0.97      0.99     71202\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# this is a batch gradient descent as\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "class LogisticRegressionCustom:\n",
    "    def __init__(self, lr, epochs, momentum = 0.9):      \n",
    "        self.lr = lr\n",
    "        self.epochs = epochs\n",
    "        self.weight = 0\n",
    "        self.bias = 0\n",
    "        self.loss = []\n",
    "        self.accuracy_record = []\n",
    "        self.weight_record = []\n",
    "        self.bias_record = []\n",
    "        self.epoch_record = []\n",
    "        self.momentum = momentum\n",
    "        self.vt_weight = 0\n",
    "        self.vt_bias = 0\n",
    "\n",
    "    def get_clean_output(self, preds):\n",
    "      threshold_prob = 0.5\n",
    "      result = preds >= threshold_prob\n",
    "      y_pred = np.zeros(result.shape[0])\n",
    "      for i in range(len(y_pred)):\n",
    "          if result[i] == True: \n",
    "              y_pred[i] = 1\n",
    "          else:\n",
    "              continue\n",
    "                 \n",
    "      return y_pred\n",
    "\n",
    "\n",
    "    def _accuracy(self, target, predictions):\n",
    "      accuracy = 0\n",
    "      for i in range(len(predictions)):\n",
    "        if (predictions[i] == target[i]):\n",
    "          accuracy += 1\n",
    "\n",
    "      return accuracy / len(target)\n",
    "\n",
    "    # Sigmoid method\n",
    "    def sigmoid(self, x, weight, bias):\n",
    "        z = np.dot(x, weight) + bias\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "     \n",
    "    # method to calculate the binary cross entropy Loss\n",
    "    def BCE_loss(self, preds, y):\n",
    "        return (-y * np.log(preds) - (1 - y) * np.log(1 - preds)).mean()\n",
    "\n",
    "    # method for calculating the gradients\n",
    "    def gradient_descent(self, X, preds, target):\n",
    "      d_loss_wrt_weight = (1 / X.shape[0]) * np.dot(X.T, (preds - target)) \n",
    "      d_loss_wrt_bias =  (1 / X.shape[0]) * np.sum(preds - target)\n",
    "      return d_loss_wrt_weight, d_loss_wrt_bias\n",
    "     \n",
    "    def fit(self, X, y, X_val, y_val):\n",
    "      self.weight = np.zeros(X.shape[1])\n",
    "      # training set\n",
    "      X = X.values\n",
    "      y = y.values\n",
    "\n",
    "      # Validation set\n",
    "      X_val = X_val.values\n",
    "      y_val = y_val.values\n",
    "\n",
    "      # training\n",
    "      for i in tqdm(range(self.epochs)):\n",
    "        predictions = self.sigmoid(X, self.weight, self.bias)\n",
    "        loss = self.BCE_loss(predictions, y)\n",
    "        dW, dB = self.gradient_descent(X, predictions, y)\n",
    "        \n",
    "        # recording items\n",
    "        self.loss.append(loss)\n",
    "        # recording validation accuracy\n",
    "        # self.accuracy_record.append(self._accuracy(y_val, self.get_clean_output(self.sigmoid(X_val, self.weight, self.bias))))\n",
    "        self.weight_record.append(self.weight)\n",
    "        self.bias_record.append(self.bias)\n",
    "        self.epoch_record.append(i)\n",
    " \n",
    "        \n",
    "        '''\n",
    "        #compute gradients with respect to theta \n",
    "        gradients = compute_gradients(data, theta)\n",
    "        #Update vt by equation (8)\n",
    "        vt = gamma * vt + lr * gradients\n",
    "        #update model parameter theta by equation (9)\n",
    "        theta = theta - vt\n",
    "        '''\n",
    "        \n",
    "        # Updating the weights using momentum\n",
    "        vt_weight = self.momentum * self.vt_weight + self.lr * dW # ya self.lr = (1- momentum) ho\n",
    "        self.weight -= vt_weight\n",
    "\n",
    "        # updating the bias/intercept using momentum\n",
    "        vt_bias = self.momentum * self.vt_bias + self.lr * dB\n",
    "        self.bias -= vt_bias\n",
    "     \n",
    "    # Method to predict the class label.\n",
    "    def predict(self, x_new):\n",
    "        test_preds = self.sigmoid(x_new, self.weight, self.bias)\n",
    "        return self.get_clean_output(test_preds)\n",
    "\n",
    "\n",
    "log_reg = LogisticRegressionCustom(0.1, 100)\n",
    "log_reg.fit(X_smote, y_smote,X_test,y_test)\n",
    "preds = log_reg.predict(X_test)\n",
    "print(\"\\nFinal Training accuracy: \",log_reg._accuracy(y_smote.values, log_reg.predict(X_smote)))\n",
    "print(\"Final Testing accuracy:, \", log_reg._accuracy(y_test.values, preds))\n",
    "\n",
    "# print classification report\n",
    "print(classification_report(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WIIK1fCEbbWp",
    "outputId": "09dafa48-8a75-4140-b962-b661c090d91c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.99     71089\n",
      "           1       0.05      0.92      0.10       113\n",
      "\n",
      "    accuracy                           0.97     71202\n",
      "   macro avg       0.53      0.95      0.54     71202\n",
      "weighted avg       1.00      0.97      0.99     71202\n",
      "\n",
      "CPU times: user 11.4 s, sys: 4.48 s, total: 15.9 s\n",
      "Wall time: 13.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# logistic regression object\n",
    "lr = LogisticRegression()\n",
    "  \n",
    "# train the model on train set\n",
    "lr.fit(X_smote, y_smote)\n",
    "  \n",
    "predictions = lr.predict(X_test)\n",
    "  \n",
    "# print classification report\n",
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yyEkKcrQUGYr"
   },
   "source": [
    "# Adam optimizer with original and custom LR model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xplwn1SZUXdy"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u4UKSfKklpik"
   },
   "source": [
    "# Original working code (Don't touch this portion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8RJClTIIZWz1"
   },
   "outputs": [],
   "source": [
    "# #### ----- ORIGINAL CODE ! DO NOT EDIT ------####\n",
    "\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# class LogisticRegression:\n",
    "#     def __init__(self, lr, epochs):      \n",
    "#         self.lr = lr\n",
    "#         self.epochs = epochs\n",
    "#         self.weight = 0\n",
    "#         self.bias = 0\n",
    "#         self.loss = []\n",
    "#         self.accuracy_record = []\n",
    "#         self.weight_record = []\n",
    "#         self.bias_record = []\n",
    "#         self.epoch_record = []\n",
    "\n",
    "\n",
    "#     def get_clean_output(self, preds):\n",
    "#       threshold_prob = 0.5\n",
    "#       result = preds >= threshold_prob\n",
    "#       y_pred = np.zeros(result.shape[0])\n",
    "#       for i in range(len(y_pred)):\n",
    "#           if result[i] == True: \n",
    "#               y_pred[i] = 1\n",
    "#           else:\n",
    "#               continue\n",
    "                 \n",
    "#       return y_pred\n",
    "\n",
    "\n",
    "#     def _accuracy(self, target, predictions):\n",
    "#       accuracy = 0\n",
    "#       for i in range(len(predictions)):\n",
    "#         if (predictions[i] == target[i]):\n",
    "#           accuracy += 1\n",
    "\n",
    "#       return accuracy / len(target)\n",
    "\n",
    "#     # using standarization for feature scaling\n",
    "#     def standardize(self, X_tr):\n",
    "#       for i in range(shape(X_tr)[1]):\n",
    "#         X_tr[:,i] = (X_tr[:,i] - np.mean(X_tr[:,i]))/np.std(X_tr[:,i])\n",
    "#       return X_tr\n",
    "\n",
    "#     # Sigmoid method\n",
    "#     def sigmoid(self, x, weight, bias):\n",
    "#         z = np.dot(x, weight) + bias\n",
    "#         return 1 / (1 + np.exp(-z))\n",
    "     \n",
    "#     # method to calculate the binary cross entropy Loss\n",
    "#     def BCE_loss(self, preds, y):\n",
    "#         return (-y * np.log(preds) - (1 - y) * np.log(1 - preds)).mean()\n",
    "\n",
    "#     # method for calculating the gradients\n",
    "#     def gradient_descent(self, X, preds, target):\n",
    "#       d_loss_wrt_weight = (1 / X.shape[0]) * np.dot(X.T, (preds - target)) \n",
    "#       d_loss_wrt_bias =  (1 / X.shape[0]) * np.sum(preds - target)\n",
    "#       return d_loss_wrt_weight, d_loss_wrt_bias\n",
    "     \n",
    "#     def fit(self, X, y, X_val, y_val):\n",
    "#       self.weight = np.zeros(X.shape[1])\n",
    "#       # training set\n",
    "#       X = self.standardize(X.values)\n",
    "#       y = y.values\n",
    "\n",
    "#       # Validation set\n",
    "#       X_val = self.standardize(X_val.values)\n",
    "#       y_val = y_val.values\n",
    "\n",
    "#       # training\n",
    "#       for i in tqdm(range(self.epochs)):\n",
    "#         predictions = self.sigmoid(X, self.weight, self.bias)\n",
    "#         loss = self.BCE_loss(predictions, y)\n",
    "#         dW, dB = self.gradient_descent(X, predictions, y)\n",
    "        \n",
    "#         # recording items\n",
    "#         self.loss.append(loss)\n",
    "#         # recording validation accuracy\n",
    "#         self.accuracy_record.append(self._accuracy(y_val, self.get_clean_output(self.sigmoid(X_val, self.weight, self.bias))))\n",
    "#         self.weight_record.append(self.weight)\n",
    "#         self.bias_record.append(self.bias)\n",
    "#         self.epoch_record.append(i)\n",
    " \n",
    "#         # Updating the weights\n",
    "#         self.weight -= self.lr * dW\n",
    "#         self.bias -= self.lr * dB\n",
    "\n",
    "\n",
    "#       print('Attempt Sucessful')\n",
    "     \n",
    "#     # Method to predict the class label.\n",
    "#     def predict(self, x_new):\n",
    "#         test_preds = self.sigmoid(x_new, self.weight, self.bias)\n",
    "#         return self.get_clean_output(test_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wDW_1-GmIDzu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Logistic_Regression.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
